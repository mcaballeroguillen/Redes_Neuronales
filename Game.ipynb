{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase del Juego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from random import randrange, choice\n",
    "class Game():\n",
    "    def __init__(self,colum,fil):\n",
    "        self.mesa= np.zeros( (fil,colum ) )\n",
    "        self.columnas=colum-1\n",
    "        self.filas=fil-1\n",
    "        self.end=0\n",
    "        self.mov=0\n",
    "        \n",
    "    def movimiento(self,colum,valor):\n",
    "        x=self.filas\n",
    "        y=colum\n",
    "        celda=self.mesa[x-1][y]\n",
    "        while(celda==0 and (x-1)>=0):\n",
    "            x=x-1\n",
    "            celda=self.mesa[x-1][y]\n",
    "        self.mesa[x][y]=valor\n",
    "        return x\n",
    "    \n",
    "    def verifica_multiplos(self,x,y):\n",
    "        valor= self.mesa[x][y]\n",
    "        suma=valor\n",
    "        #Celda de arriba\n",
    "        if(x-1>=0):\n",
    "            if(self.mesa[x-1][y]==valor):\n",
    "                suma=suma+self.mesa[x-1][y]\n",
    "                self.mesa[x-1][y]=0.0\n",
    "        #Celda de Abajo\n",
    "        if(x+1<=self.filas):\n",
    "            if(self.mesa[x+1][y]==valor):\n",
    "                suma=suma+self.mesa[x+1][y]\n",
    "                self.mesa[x+1][y]=0.0\n",
    "        #Celda izquierda\n",
    "        if(y-1>=0):\n",
    "            if(self.mesa[x][y-1]==valor):\n",
    "                suma=suma+self.mesa[x][y-1]\n",
    "                self.mesa[x][y-1]=0.0\n",
    "        #Celda derecha\n",
    "        if(y+1<=self.columnas):\n",
    "            if(self.mesa[x][y+1]==valor):\n",
    "                suma=suma+self.mesa[x][y+1]\n",
    "                self.mesa[x][y+1]=0.0\n",
    "        if(valor!=suma):\n",
    "            self.mesa[x][y]=suma\n",
    "            self.verifica_multiplos(x,y)\n",
    "            \n",
    "        self.verificar_espacios()\n",
    "        \n",
    "    def verificar_espacios(self):\n",
    "        for x in range(self.filas+1):\n",
    "            for y in range(self.columnas+1):\n",
    "                if(x+1<=self.filas):\n",
    "                    if(self.mesa[x][y]==0.0 and self.mesa[x+1][y]!=0.0):\n",
    "                        self.mesa[x][y]=self.mesa[x+1][y]\n",
    "                        self.mesa[x+1][y]=0.0\n",
    "                        self.verifica_multiplos(x,y)\n",
    "        self.verificar_end()\n",
    "    \n",
    "    def verificar_end(self):\n",
    "        for y in range(self.columnas+1):\n",
    "            if(self.mesa[self.filas][y]!=0.0):\n",
    "                self.end=1\n",
    "                \n",
    "    def run(self):\n",
    "        \n",
    "        while(self.end==0):\n",
    "            clear_output()\n",
    "            print(self.mesa)\n",
    "            valor= choice([2.0,4.0,8.0,16.0,32.0])\n",
    "            print(valor)\n",
    "            y=int(input())\n",
    "            x= self.movimiento(y,valor)\n",
    "            self.verifica_multiplos(x,y)\n",
    "        print(self.mesa)\n",
    "                \n",
    "       \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.   0.   0.]\n",
      " [  2.   0.   0.]\n",
      " [  4.   0.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [  2.   0.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "4.0\n",
      "0\n",
      "[[  8.   0.   0.]\n",
      " [  2.   0.   0.]\n",
      " [  4.   0.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [  2.   0.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [  4.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "game= Game(3,7)\n",
    "game.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Código de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "#\"\"\" Clase que representa la capa de un perceptron sigmoide\"\"\"\n",
    "class Perceptron: \n",
    "    def __init__(self):\n",
    "        self.pesos= [] # \"\"\"Arreglo donde se guardan los pesos\"\"\"\n",
    "        self.datos=[]  #\"\"\" Arreglo donde se guardan los inputs\"\"\"\n",
    "        self.b=0  #\"\"\"Este valor representa el bais\"\"\"\n",
    "        self.out=0 #\"\"\" Este valor represente el output del sigmoide\"\"\"\n",
    "        self.error=0 #\"\"\" El error \"\"\"\n",
    "        self.delta=0  #\"\"\" El delta\"\"\"\n",
    "        self.lr=0.1 #\"\"\" El learning rata\"\"\"\n",
    "        self.bout=0  # \"\"\"Este valor represente en binario el output, por si se necesita\"\"\"\n",
    "    \n",
    "   # \"\"\" Método para agregar el learning rate\"\"\"\n",
    "    def agregarlr(self,valor):\n",
    "        self.lr=valor\n",
    "    #\"\"\" Agregar pesos\"\"\"\n",
    "    def agregarpeso(self,peso):\n",
    "        self.pesos.append(peso)\n",
    "    #\"\"\" Agregar los inputs\"\"\"    \n",
    "    def agregardato(self,dato):\n",
    "        self.datos.append(dato)\n",
    "    #\"\"\" Agregar bais\"\"\"    \n",
    "    def agregarbais(self,bais):\n",
    "        self.b=bais\n",
    "     #\"\"\"Agregar erro, este se utiliza si este perectron está en la última capa \"\"\"\"\n",
    "      #   \"\"\"ya que aquí el erro es la resta del output con el output esperado \"\"\"   \n",
    "    def agregarerror(self,valor):\n",
    "        self.error=valor\n",
    "   # \"\"\" Calcular el output del sigmoide, ya debe estar ingresados lo datos y los pesos\"\"\"\n",
    "    def run(self):\n",
    "        ps=np.array(self.pesos)\n",
    "        dt=np.array(self.datos)\n",
    "        x= ps*dt\n",
    "        suma=x.sum()\n",
    "        exponente = -1*(suma+self.b)\n",
    "        denominador = 1 + np.exp(exponente)\n",
    "        self.out=1/denominador\n",
    "        if self.out>=0.5: #\"\"\"Criterio para calcular el output binario\"\"\"\n",
    "            self.bout=1\n",
    "        else:\n",
    "            self.bout=0\n",
    "    #\"\"\"Agregar datos\"\"\"\n",
    "    def agregardatos(self,dats):\n",
    "        self.datos=dats\n",
    "     #\"\"\"Vaciar datos\"\"\"   \n",
    "    def vaciardatos(self):\n",
    "        self.datos=[]\n",
    "        \n",
    "    #\"\"\"Calcular error, ingresando los delta de la capa siguiente\"\"\"\n",
    "    def calcularerror(self,deltasnextcapa,pesosnextcapa):\n",
    "        ps=np.array(pesosnextcapa)\n",
    "        delt=np.array(deltasnextcapa)\n",
    "        \n",
    "        mult=ps*delt\n",
    "        self.error=mult.sum()\n",
    "    #\"\"\"Calcular del delta\"\"\"    \n",
    "    def calculardelta(self):\n",
    "        self.delta=self.error*(self.out*(1-self.out))\n",
    "    \n",
    "    #Despues de tener el delta se realiza el ajuste de los pesos, este se usa\n",
    "    #para el paso 3 de la backpropagation. \n",
    "    def ajustarpesos(self):\n",
    "        nuevospesos=[]\n",
    "        x=0\n",
    "        for peso in self.pesos:\n",
    "            nuevospesos.append(peso+(self.lr*self.delta*self.datos[x]))\n",
    "            x=x+1\n",
    "        self.pesos=nuevospesos\n",
    "        self.b=self.b + self.lr*self.delta    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Capa:\n",
    "    #\"\"\"Clase que representa una capa de red neuronal\"\"\"\n",
    "    def __init__(self):\n",
    "        self.perceptrones=[] #\"\"\"Arreglo con los pereceptrones\"\"\"\n",
    "        self.input=[] #\"\"\"Inputs que se le pasaran a  los pereceptrones \"\"\"\n",
    "        self.output=[] # \"\"\"Outputs que regresaran los perceptrones\"\"\"\n",
    "        self.deltas=[]  #\"\"\"Deltas de cada uno de los perceptrones \"\"\"\n",
    "        self.siguientecapa = None # \"\"\"Siguiente capa\"\"\"\n",
    "        self.anteriorcapa =None  # \"\"\"Capa anterior\"\"\"\n",
    "        self.boutput=[]\n",
    "        self.pesos=[]  #Arreglo que guarda los pesos de cada perceptron, arreglo de arreglos\n",
    "    def getnextcapa(self, capa):\n",
    "        self.siguientecapa = capa\n",
    "    \n",
    "    def getpreviouscapa(self,capa):\n",
    "        self.anteriorcapa = capa\n",
    "   # \"\"\"Agregar inputs\"\"\"\n",
    "    def getinput(self,datos):\n",
    "        self.input=datos\n",
    "    # Agregar perceptron individual\n",
    "    def getperceptron(self, perceptron):\n",
    "        self.perceptrones.append(perceptron)\n",
    "        self.pesos.append(perceptron.pesos)\n",
    "   \n",
    "    #Cargar los pesos de los perceptrones\n",
    "    def cargarpesos(self):\n",
    "        pesos=[]\n",
    "        for per in self.perceptrones:\n",
    "            pesos.append(per.pesos)\n",
    "        self.pesos=pesos\n",
    "    # Agregar perceptrones arreglo     \n",
    "    def setperceptrones(self, arreglo):\n",
    "        self.perceptrones=arreglo\n",
    "        pesos=[]\n",
    "        for per in arreglo:\n",
    "            pesos.append(per.pesos)\n",
    "        self.pesos=pesos\n",
    "        \n",
    "   #\"\"\"Recorrido para calcular output \"\"\"\n",
    "    def Feeding(self):\n",
    "        self.output=[]\n",
    "        self.boutput=[]\n",
    "        for perc in self.perceptrones: #\"\"\"Cada perceptron recibe los datos y su respuestas son cargadas al outputs\"\"\"\n",
    "            perc.agregardatos(self.input)\n",
    "            perc.run()\n",
    "            self.output.append(perc.out)\n",
    "            self.boutput.append(perc.bout)\n",
    "        if self.siguientecapa != None: #\"\"\"Si no es la última capa, se pasá mi output como input de la siguiente capa\"\"\"\n",
    "            self.siguientecapa.getinput(self.output)\n",
    "            self.siguientecapa.Feeding()\n",
    "    \n",
    "   #Método backprogation para la última cap, recibe un arreglo con los output esperados\n",
    "\n",
    "    def backpropagation(self, expectoutput):\n",
    "        self.deltas=[] #Vaciamo los deltas\n",
    "        x=0\n",
    "        for perc in self.perceptrones:\n",
    "            perc.agregarerror(expectoutput[x]-perc.out)# \"\"\"Cada pereceptron recibe su error\"\"\"\n",
    "            perc.calculardelta()#\"\"\"Cada perceptron calcula su delta\"\"\"\n",
    "            self.deltas.append(perc.delta) #\"\"\"Se agregan a los delta de la capaa \"\"\"\n",
    "            x=x+1\n",
    "        self.anteriorcapa.backpropagation1(self.deltas,self.pesos) #Backpropagation para otreas capas. \n",
    "        #Despues se propaga el error, comenzamos a ajustar los pesos.\n",
    "        for perc in self.perceptrones:\n",
    "            perc.ajustarpesos()\n",
    "        self.cargarpesos()\n",
    "    #Métod backpropagation para capas distan a las final,recibe los deltas y pesos de la sigueinte capa.     \n",
    "    def backpropagation1(self,deltas,pesos):\n",
    "        self.deltas=[] #Vaciamos los deltas\n",
    "        x=0\n",
    "        for perc in self.perceptrones:\n",
    "            pecorres=[] #Pesos correspondientes para un perceptron específico\n",
    "            for pp in pesos: #pp es un arreglo con los pesos de un perceptron de la capa siguiente\n",
    "                pecorres=pp[x]     #Sacamos nuestro peso correspondiente de ese perceotron\n",
    "            perc.calcularerror(deltas,pecorres) # El perecptron calcula el erro\n",
    "            perc.calculardelta() # El perceptron calcula el delta.\n",
    "            self.deltas.append(perc.delta) #Agregamos el delta al arreglo de la capa\n",
    "            x=x+1\n",
    "        if(self.anteriorcapa==None): #Si es la primera capa, detemos la propagación\n",
    "            for perc in self.perceptrones: \n",
    "                perc.ajustarpesos() # Paso 3 de el backpropagation, ajustamos los pesos\n",
    "            self.cargarpesos() #Cargamos lo pesos al arreglo de la capa\n",
    "        else:\n",
    "            self.anteriorcapa.backpropagation1(self.deltas,self.pesos) #Seguimos con la propagación\n",
    "            for perc in self.perceptrones:\n",
    "                perc.ajustarpesos() #Al terminar la propagación ajustamos los pesos.\n",
    "            self.cargarpesos()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Fabrica:\n",
    "    def __init__(self):\n",
    "        self.lr=0.1 #learning range con el que se crearn los perceptrones\n",
    "        self.bais=-1 #bais con el que se crearan los peceptrones\n",
    "        \n",
    "    def getlr(self,valor):\n",
    "        self.lr=valor\n",
    "        \n",
    "    def getbais(self,valor):\n",
    "        self.bais=valor\n",
    "    #Método que crea un perecpetron con cantidad especifica de pesos   \n",
    "    def crearPerceptron(self,cantPesos):\n",
    "        per= Perceptron()\n",
    "        for x in range(cantPesos):\n",
    "            per.agregarpeso(uniform(-2,2))\n",
    "        per.agregarlr(self.lr)\n",
    "        per.agregarbais(self.bais)\n",
    "        return per\n",
    "    #Método que crea una capa con una cantidad especifica de perceptrones y pesos.\n",
    "    def crearCapa(self, cantPer, cantPesos):\n",
    "        cap= Capa()\n",
    "        for x in range(cantPer):\n",
    "            cap.getperceptron(self.crearPerceptron(cantPesos))\n",
    "        return cap    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Red_Neuronal:\n",
    "    def __init__(self):\n",
    "        self.capinicial=None #Capa inicial \n",
    "        self.capintemedias=[] #Arreglo donde se guardaran las capas intemedias, deben ser ingresadas en orden.\n",
    "        self.capfinal=None\n",
    "    #Se agrega la capa incial a la red neuronal, se asume que esta tiene los perceptrones y pesos correctos.\n",
    "    def setcapinicial(self,capa):\n",
    "        self.capinicial=capa\n",
    "    #Agregar capa final.\n",
    "    def setcapfinal(self, capa):\n",
    "        self.capfinal= capa\n",
    "    #Agregar una capa intemedia, se debe agregar en orden\n",
    "    def setcapaintermedia(self, capa):\n",
    "        self.capintemedias.append(capa)\n",
    "    #Método para que cada capa reciba su capa anterior y su capa siguiente    \n",
    "    def enlazar(self):\n",
    "        if len(self.capintemedias)==0: #Si no hay capas intermedias\n",
    "            self.capinicial.getnextcapa(self.capfinal)   #Se enlazan la primera con la última\n",
    "            self.capfinal.getpreviouscapa(self.capinicial)\n",
    "        else:  #Si hay capas intemedias\n",
    "            x=0\n",
    "            self.capinicial.getnextcapa(self.capintemedias[x]) #Se enlaza la capa inicial, con la primera capa del arreglo\n",
    "            while x<(len(self.capintemedias)-1):\n",
    "                self.capintemedias[x].getnextcapa(self.capintemedias[x+1]) #Se enlaza cada capa, con su siguiente\n",
    "                x=x+1\n",
    "            x=len(self.capintemedias)-1\n",
    "            while x>0:\n",
    "                self.capintemedias[x].getpreviouscapa(self.capintemedias[x-1])#Se enlaza cada capa, con la anterior\n",
    "                x=x-1\n",
    "            x=len(self.capintemedias)-1\n",
    "            self.capfinal.getpreviouscapa(self.capintemedias[x]) #Se enlza la  útima capa del arrglo, con la capa final\n",
    "            self.capintemedias[x].getnextcapa(self.capfinal)\n",
    "    \n",
    "    def comparador(self,conjunto1,conjunto2):\n",
    "        x=1\n",
    "        i=0\n",
    "        for z in conjunto1:\n",
    "            if(z!=conjunto2[i]):\n",
    "                x=0\n",
    "                return x\n",
    "            i=i+1\n",
    "        return x\n",
    "    \n",
    "    #Método para entrenar, devuelve los errores\n",
    "    def entrenar(self,settrain,num, settest):\n",
    "        inputrain=settrain[0]\n",
    "        outputtrain=settrain[1]\n",
    "        inputtest=settest[0]\n",
    "        outputtest=settest[1]\n",
    "        intentos=[]\n",
    "        resultados=[]\n",
    "        \n",
    "        for x in range(num):\n",
    "            i=0\n",
    "            for tupla in inputrain:\n",
    "                self.capinicial.getinput(tupla)\n",
    "                self.capinicial.Feeding()\n",
    "                self.capfinal.backpropagation(outputtrain[i])\n",
    "                i=i+1\n",
    "            i=0\n",
    "            errores=0\n",
    "            for tupla in inputtest:\n",
    "                self.capinicial.getinput(tupla)\n",
    "                self.capinicial.Feeding()\n",
    "                if self.comparador(self.capfinal.boutput,outputtest[i])==0:\n",
    "                    errores=errores+1\n",
    "                i=i+1\n",
    "            resultados.append(errores)\n",
    "            intentos.append(x+1)\n",
    "        return [intentos,resultados]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código Algóritmo Genético "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random, randrange \n",
    "class Genetic_Algoritmo:\n",
    "    def __init__(self):\n",
    "        self.Mutation_Rate=0.01\n",
    "        self.Genes=0\n",
    "        self.Population=[]\n",
    "        self.Evaluation=[]\n",
    "        self.Generador=None\n",
    "        self.Fitness=None\n",
    "        self.Selecction=[]\n",
    "    \n",
    "    def genera_popinicial(self, num):\n",
    "        for x in range(num):\n",
    "            indiv=[]\n",
    "            for w in range(self.Genes):\n",
    "                indiv.append(self.Generador(w))\n",
    "            self.Population.append(indiv)\n",
    "    \n",
    "    def Evaluate(self):\n",
    "        self.Evaluation=[]\n",
    "        for x in range(len(self.Population)):\n",
    "            self.Evaluation.append(self.Fitness(self.Population[x]))\n",
    "    \n",
    "    def Tournament_selection(self,k):\n",
    "        ind=-1;\n",
    "        for x in range(k):\n",
    "            r= randrange(len(self.Population)) \n",
    "            if(ind==-1 or self.Evaluation[r]>self.Evaluation[ind]):\n",
    "                ind=r\n",
    "        self.Selecction.append(self.Population[ind])\n",
    "        \n",
    "    def Reproduction(self):\n",
    "        largo=len(self.Population)\n",
    "        newPop=[]\n",
    "        self.Selecction=[]\n",
    "        for x in range(2*largo):\n",
    "            self.Tournament_selection(5)\n",
    "        for x in range(largo):\n",
    "            newindv=[]\n",
    "            indiv1= self.Selecction[x]\n",
    "            indiv2= self.Selecction[x+largo]\n",
    "            point_mixing= randrange(self.Genes)\n",
    "            for x in range(self.Genes):\n",
    "                if(x>point_mixing):\n",
    "                    newindv.append(indiv2[x])\n",
    "                else:\n",
    "                    newindv.append(indiv1[x])\n",
    "            i=0\n",
    "            for gen in newindv:\n",
    "                rand= random()\n",
    "                if rand<self.Mutation_Rate:\n",
    "                    newgen=self.Generador(i)\n",
    "                    newindv[i]=newgen\n",
    "                i=i+1\n",
    "            newPop.append(newindv)\n",
    "        self.Population=newPop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randrange, choice,uniform\n",
    "game= Game(3,7)\n",
    "fabri= Fabrica()\n",
    "def normalizar(arreglo):\n",
    "    salida=[]\n",
    "    for x in arreglo:\n",
    "        salida.append(x/1024)\n",
    "    return salida\n",
    "\n",
    "def Generador(ind):\n",
    "    if(ind<25):\n",
    "        return fabri.crearPerceptron(22)\n",
    "    else:\n",
    "        return fabri.crearPerceptron(25)\n",
    "    \n",
    "def MaxValoMesa(mesa):\n",
    "    maxx=0;\n",
    "    for fila in mesa:\n",
    "        for valor in fila:\n",
    "            if (valor>maxx):\n",
    "                maxx=valor\n",
    "    return maxx\n",
    "    \n",
    "def Evaluador(indv):\n",
    "    game= Game(3,7)\n",
    "    acapa1=[]\n",
    "    acapa2=[]\n",
    "    for x in range(28):\n",
    "        if(x<25):\n",
    "            acapa1.append(indv[x])\n",
    "        else:\n",
    "            acapa2.append(indv[x])\n",
    "    Capa1= Capa()\n",
    "    Capa2=Capa()\n",
    "    Capa1.setperceptrones(acapa1)\n",
    "    Capa2.setperceptrones(acapa2)\n",
    "    red1= Red_Neuronal()\n",
    "    red1.setcapinicial(Capa1) #Capa incial.\n",
    "    red1.setcapfinal(Capa2) #Capa final\n",
    "    red1.enlazar()\n",
    "    mov=0\n",
    "    while(game.end==0):\n",
    "        valor= choice([2.0,4.0,8.0,16.0,32.0])\n",
    "        entrada=[]\n",
    "        entrada.append(valor)\n",
    "        for fila in game.mesa:\n",
    "            for celda in fila:\n",
    "                entrada.append(celda)\n",
    "        red1.capinicial.getinput(normalizar(entrada))\n",
    "        red1.capinicial.Feeding()\n",
    "        \n",
    "        outp=red1.capfinal.output\n",
    "        i=0\n",
    "        maxx=0\n",
    "        i2=0\n",
    "        for xot in outp:\n",
    "            if(maxx<=xot):\n",
    "                i2=i\n",
    "                maxx=xot\n",
    "            i=i+1\n",
    "        x= game.movimiento(i2,valor)\n",
    "        game.verifica_multiplos(x,i2)\n",
    "        #print(game.mesa)\n",
    "        mov=mov+1\n",
    "    return mov\n",
    "\n",
    "def verjugar(indv):\n",
    "    game= Game(3,7)\n",
    "    print(\"ss\")\n",
    "    acapa1=[]\n",
    "    acapa2=[]\n",
    "    for x in range(28):\n",
    "        if(x<25):\n",
    "            acapa1.append(indv[x])\n",
    "        else:\n",
    "            acapa2.append(indv[x])\n",
    "    Capa1= Capa()\n",
    "    Capa2= Capa()\n",
    "    Capa1.setperceptrones(acapa1)\n",
    "    Capa2.setperceptrones(acapa2)\n",
    "    red1= Red_Neuronal()\n",
    "    red1.setcapinicial(Capa1) #Capa incial.\n",
    "    red1.setcapfinal(Capa2) #Capa final\n",
    "    red1.enlazar()\n",
    "    mov=0\n",
    "    while(game.end==0):\n",
    "        valor= choice([2.0,4.0,8.0,16.0,32.0])\n",
    "        entrada=[]\n",
    "        entrada.append(valor)\n",
    "        for fila in game.mesa:\n",
    "            for celda in fila:\n",
    "                entrada.append(celda)\n",
    "        red1.capinicial.getinput(normalizar(entrada))\n",
    "        red1.capinicial.Feeding()\n",
    "        \n",
    "        outp=red1.capfinal.output\n",
    "        i=0\n",
    "        maxx=0\n",
    "        i2=0\n",
    "        for xot in outp:\n",
    "            if(maxx<=xot):\n",
    "                i2=i\n",
    "                maxx=xot\n",
    "            i=i+1\n",
    "        x= game.movimiento(i2,valor)\n",
    "        game.verifica_multiplos(x,i2)\n",
    "        print(game.mesa)\n",
    "        mov=mov+1\n",
    "        print(mov)\n",
    "Genetic1 = Genetic_Algoritmo()\n",
    "Genetic1.Fitness=Evaluador\n",
    "Genetic1.Generador=Generador\n",
    "Genetic1.Genes=28\n",
    "Genetic1.genera_popinicial(1000)\n",
    "Genetic1.Evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 13, 8, 9, 8, 9, 8, 11, 17, 9, 9, 9, 8, 7, 8, 7, 7, 12, 8, 8, 8, 10, 8, 7, 10, 8, 13, 7, 7, 8, 7, 8, 13, 8, 8, 10, 9, 9, 11, 9, 8, 7, 8, 9, 8, 8, 7, 8, 12, 7, 10, 12, 7, 8, 8, 8, 13, 10, 7, 7, 8, 12, 7, 9, 8, 8, 9, 9, 7, 8, 8, 11, 8, 10, 9, 8, 8, 7, 8, 7, 7, 10, 8, 7, 8, 7, 8, 7, 7, 7, 7, 9, 7, 9, 8, 8, 8, 8, 8, 7, 11, 7, 12, 11, 15, 8, 8, 8, 7, 7, 10, 12, 10, 7, 9, 8, 9, 8, 12, 9, 8, 9, 10, 8, 7, 8, 10, 10, 7, 7, 7, 8, 8, 10, 11, 11, 10, 9, 9, 11, 7, 7, 10, 8, 10, 7, 17, 7, 10, 8, 8, 10, 9, 11, 7, 8, 8, 8, 10, 7, 9, 8, 8, 8, 7, 7, 10, 9, 7, 8, 7, 8, 9, 13, 7, 8, 7, 9, 7, 8, 9, 7, 12, 8, 9, 12, 9, 8, 9, 8, 8, 9, 9, 7, 8, 9, 8, 7, 9, 8, 8, 11, 9, 7, 9, 9, 8, 7, 8, 9, 8, 9, 8, 7, 7, 7, 8, 7, 13, 9, 8, 8, 7, 10, 7, 11, 10, 10, 7, 7, 10, 8, 7, 9, 9, 8, 9, 17, 7, 9, 7, 8, 7, 9, 8, 12, 7, 9, 8, 10, 8, 10, 7, 7, 8, 12, 7, 10, 11, 7, 7, 8, 8, 10, 8, 7, 7, 8, 10, 7, 10, 7, 8, 7, 8, 10, 10, 10, 8, 9, 8, 11, 11, 7, 10, 7, 7, 8, 8, 7, 9, 7, 13, 10, 9, 9, 8, 12, 8, 8, 10, 11, 7, 8, 7, 13, 12, 8, 8, 8, 7, 8, 9, 19, 11, 8, 9, 8, 8, 7, 7, 8, 10, 7, 8, 13, 10, 9, 9, 7, 7, 7, 10, 9, 8, 7, 12, 8, 7, 8, 10, 9, 8, 8, 9, 9, 8, 8, 10, 11, 10, 9, 10, 8, 8, 11, 7, 8, 8, 7, 9, 11, 11, 8, 9, 7, 7, 8, 7, 11, 10, 7, 8, 7, 7, 8, 11, 9, 10, 7, 7, 10, 8, 8, 9, 9, 7, 7, 8, 8, 8, 11, 8, 8, 8, 9, 9, 8, 9, 9, 8, 9, 7, 7, 13, 10, 11, 9, 11, 7, 8, 7, 9, 12, 7, 13, 11, 8, 8, 7, 10, 8, 9, 12, 12, 10, 7, 9, 8, 7, 9, 7, 7, 7, 9, 9, 7, 7, 9, 11, 8, 12, 7, 8, 10, 9, 9, 9, 7, 14, 7, 7, 7, 7, 8, 9, 10, 8, 7, 8, 8, 12, 10, 13, 11, 7, 8, 10, 7, 7, 8, 8, 9, 8, 10, 7, 7, 7, 12, 8, 7, 9, 8, 7, 9, 8, 10, 12, 10, 10, 11, 7, 10, 10, 7, 11, 9, 8, 7, 8, 8, 8, 7, 10, 11, 9, 13, 9, 8, 7, 7, 9, 11, 9, 10, 8, 7, 10, 13, 8, 7, 9, 9, 10, 10, 9, 8, 8, 7, 9, 12, 8, 7, 8, 8, 7, 7, 11, 10, 8, 10, 8, 7, 11, 9, 10, 16, 8, 12, 9, 10, 8, 7, 7, 8, 8, 8, 8, 7, 9, 9, 8, 14, 8, 8, 9, 9, 8, 12, 8, 13, 13, 8, 10, 11, 10, 13, 9, 7, 7, 9, 7, 10, 10, 8, 11, 8, 8, 9, 7, 10, 9, 8, 7, 8, 7, 9, 7, 8, 9, 10, 7, 9, 8, 9, 7, 10, 7, 8, 7, 9, 9, 8, 8, 8, 11, 8, 9, 7, 7, 21, 7, 9, 11, 8, 10, 9, 8, 9, 8, 10, 7, 7, 9, 9, 7, 10, 7, 9, 9, 11, 15, 7, 7, 7, 7, 9, 8, 11, 11, 7, 10, 8, 7, 8, 8, 9, 11, 10, 8, 8, 7, 16, 9, 10, 8, 8, 11, 8, 7, 8, 7, 10, 7, 8, 13, 8, 11, 9, 10, 11, 8, 8, 17, 7, 9, 7, 8, 7, 12, 10, 10, 8, 7, 9, 7, 7, 8, 12, 8, 7, 9, 8, 9, 8, 8, 7, 9, 9, 10, 7, 12, 7, 9, 9, 9, 7, 7, 7, 7, 12, 10, 7, 7, 9, 8, 8, 10, 7, 8, 7, 8, 10, 7, 8, 12, 8, 9, 15, 7, 10, 8, 9, 8, 10, 7, 8, 12, 7, 12, 8, 8, 9, 8, 8, 7, 8, 8, 9, 10, 7, 7, 13, 10, 10, 8, 10, 8, 11, 8, 8, 8, 9, 7, 7, 7, 9, 7, 10, 8, 7, 8, 8, 9, 8, 9, 8, 8, 8, 11, 9, 8, 9, 10, 7, 7, 7, 7, 9, 8, 7, 8, 9, 9, 10, 22, 13, 10, 10, 8, 8, 8, 8, 8, 8, 7, 7, 11, 11, 8, 14, 10, 10, 7, 8, 8, 9, 9, 7, 7, 8, 12, 9, 9, 7, 8, 9, 12, 11, 13, 8, 7, 9, 7, 10, 9, 9, 15, 9, 14, 7, 11, 8, 9, 13, 7, 10, 7, 11, 12, 7, 10, 10, 16, 7, 8, 8, 9, 7, 7, 7, 8, 7, 10, 10, 9, 10, 8, 7, 7, 8, 9, 11, 8, 9, 13, 12, 7, 7, 7, 7, 9, 9, 9, 11, 9, 10, 9, 10, 8, 10, 7, 7, 8, 9, 8, 8, 10, 11, 8, 8, 8, 10, 8, 8, 8, 9, 8, 7, 9, 9, 8, 8, 10, 8, 8, 10, 16, 8, 7, 12, 8, 12, 7, 11, 10, 8, 7, 9, 8, 7, 10, 7, 10, 9, 8, 7, 15, 10, 10, 8, 8, 7, 8, 7, 8, 10, 10, 9, 9, 11, 7, 8, 9, 9, 9, 7, 11, 9, 8, 9, 10, 9, 10, 7, 8, 7, 9, 8, 10, 9, 9, 8, 9, 8, 15, 10, 7, 8, 9, 10, 11, 10, 8, 7, 21, 7, 7, 12, 9]\n"
     ]
    }
   ],
   "source": [
    "print(Genetic1.Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 64, 41, 34, 29, 28, 31, 40, 31, 40, 35, 24, 31, 20, 24, 33, 29, 43, 44, 29, 31, 16, 14, 39, 33, 31, 33, 47, 37, 31, 11, 44, 25, 32, 41, 20, 27, 36, 25, 25, 39, 36, 40, 28, 43, 13, 36, 29, 27, 39, 29, 13, 27, 25, 31, 35, 68, 9, 32, 16, 32, 23, 29, 27, 33, 25, 45, 25, 29, 36, 31, 34, 22, 32, 37, 39, 33, 45, 11, 47, 18, 24, 22, 33, 47, 8, 26, 48, 43, 26, 32, 36, 33, 36, 52, 26, 48, 41, 22, 40, 34, 18, 44, 28, 46, 16, 17, 25, 17, 22, 27, 44, 17, 35, 22, 23, 28, 33, 36, 13, 30, 34, 30, 29, 23, 47, 41, 34, 36, 34, 45, 21, 27, 36, 31, 21, 45, 31, 33, 41, 40, 15, 31, 48, 39, 37, 7, 23, 16, 11, 24, 22, 14, 34, 31, 20, 33, 40, 35, 23, 22, 31, 26, 47, 25, 33, 32, 21, 39, 26, 30, 32, 27, 28, 40, 30, 27, 39, 39, 28, 42, 36, 18, 33, 35, 38, 34, 41, 25, 29, 44, 29, 30, 41, 17, 32, 14, 29, 39, 34, 24, 26, 25, 21, 49, 26, 25, 39, 27, 26, 39, 32, 21, 30, 31, 45, 24, 36, 45, 50, 44, 32, 34, 19, 44, 33, 10, 54, 36, 21, 28, 27, 23, 42, 13, 17, 30, 35, 32, 36, 20, 26, 27, 19, 55, 33, 40, 13, 24, 16, 38, 32, 18, 33, 35, 20, 19, 27, 38, 23, 53, 17, 20, 62, 34, 21, 29, 18, 15, 38, 31, 25, 19, 40, 30, 45, 24, 31, 34, 37, 44, 45, 20, 43, 33, 36, 21, 32, 47, 23, 28, 14, 19, 32, 34, 31, 23, 33, 42, 39, 39, 35, 26, 24, 40, 16, 27, 38, 49, 29, 28, 16, 51, 20, 35, 33, 32, 34, 34, 29, 20, 30, 19, 38, 44, 30, 30, 33, 34, 21, 34, 25, 22, 31, 25, 28, 32, 40, 25, 22, 38, 50, 42, 34, 32, 34, 34, 35, 19, 22, 36, 45, 32, 28, 25, 27, 29, 21, 37, 33, 22, 45, 25, 42, 23, 55, 49, 18, 46, 21, 27, 30, 36, 25, 30, 14, 37, 21, 36, 26, 23, 23, 24, 24, 33, 32, 34, 48, 28, 15, 52, 22, 9, 41, 49, 22, 33, 26, 57, 47, 46, 39, 34, 38, 26, 25, 35, 35, 17, 19, 25, 24, 28, 22, 37, 41, 31, 38, 25, 42, 30, 23, 37, 18, 38, 31, 38, 40, 25, 25, 24, 31, 31, 28, 43, 29, 30, 37, 23, 14, 27, 44, 29, 17, 27, 36, 39, 18, 29, 28, 20, 27, 50, 14, 27, 33, 22, 24, 38, 31, 50, 34, 31, 30, 41, 22, 26, 34, 26, 37, 21, 36, 26, 40, 22, 15, 33, 21, 29, 27, 19, 32, 16, 55, 25, 32, 34, 21, 32, 12, 36, 27, 42, 32, 29, 37, 18, 37, 33, 27, 37, 33, 19, 23, 34, 26, 49, 35, 30, 17, 30, 22, 34, 36, 33, 33, 17, 47, 38, 30, 27, 29, 37, 26, 40, 14, 22, 35, 32, 42, 11, 56, 27, 35, 24, 22, 32, 24, 30, 8, 36, 36, 32, 29, 22, 23, 29, 57, 36, 25, 29, 10, 10, 13, 43, 51, 34, 23, 35, 37, 21, 17, 28, 36, 18, 37, 44, 16, 21, 24, 24, 33, 30, 30, 28, 36, 22, 35, 30, 30, 39, 34, 24, 15, 32, 19, 28, 21, 33, 20, 14, 20, 43, 19, 42, 57, 42, 57, 21, 24, 14, 14, 35, 39, 26, 47, 23, 27, 31, 17, 30, 29, 32, 27, 26, 33, 29, 54, 29, 27, 55, 43, 13, 29, 38, 20, 26, 20, 34, 43, 47, 20, 26, 25, 30, 29, 24, 36, 28, 28, 16, 21, 43, 40, 27, 35, 29, 33, 33, 28, 40, 39, 24, 24, 48, 31, 8, 19, 11, 19, 28, 17, 27, 28, 35, 19, 24, 38, 23, 36, 32, 23, 34, 18, 38, 35, 20, 56, 37, 25, 44, 27, 35, 29, 25, 56, 38, 39, 20, 28, 45, 39, 30, 32, 30, 12, 23, 24, 42, 25, 53, 23, 24, 42, 33, 39, 27, 29, 48, 10, 26, 49, 20, 31, 30, 34, 34, 37, 37, 32, 33, 35, 22, 46, 28, 39, 24, 23, 30, 17, 45, 19, 30, 29, 7, 37, 32, 27, 44, 45, 32, 18, 16, 22, 14, 18, 48, 34, 47, 34, 26, 24, 29, 23, 35, 38, 24, 26, 49, 34, 26, 36, 9, 8, 35, 17, 34, 27, 30, 20, 15, 22, 46, 27, 31, 32, 22, 40, 45, 41, 48, 36, 21, 33, 35, 20, 20, 61, 45, 27, 7, 27, 41, 38, 17, 19, 25, 25, 40, 35, 48, 26, 38, 44, 33, 35, 9, 42, 40, 35, 47, 38, 43, 36, 43, 19, 39, 35, 36, 31, 32, 31, 43, 14, 13, 29, 35, 39, 42, 32, 28, 27, 33, 33, 33, 35, 29, 32, 33, 30, 23, 32, 43, 34, 29, 29, 32, 41, 23, 41, 23, 25, 46, 18, 25, 42, 36, 44, 22, 27, 24, 27, 36, 28, 33, 27, 24, 21, 26, 18, 36, 32, 41, 27, 30, 30, 24, 31, 42, 30, 19, 40, 41, 33, 31, 40, 19, 30, 26, 49, 32, 30, 34, 46, 8, 31, 25, 30, 18, 48, 28, 9, 36, 40, 25, 41, 16, 29, 38, 39, 37, 43, 30, 21, 43, 43, 23, 31, 14, 18, 24, 40, 22, 27, 39, 33, 28, 32, 31, 30, 28, 24, 32, 28, 18, 24, 21, 32, 28, 31, 23, 27, 24, 35, 22, 33, 21, 28, 61, 20, 26, 35, 33, 40, 15, 25, 20, 63, 32, 39, 31, 23, 22, 33, 28, 20, 41, 36, 36, 32, 50, 28, 15, 27, 33, 40, 31, 34, 19, 42, 35, 38, 30, 31, 38, 38, 32, 29, 36, 29, 31, 33, 29, 27, 26, 19, 28, 26, 38, 26]\n"
     ]
    }
   ],
   "source": [
    "for x in range(200):\n",
    "    Genetic1.Reproduction()\n",
    "    Genetic1.Evaluate()\n",
    "print(Genetic1.Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 68\n",
      "ss\n",
      "[[ 16.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "1\n",
      "[[ 16.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "2\n",
      "[[ 16.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "3\n",
      "[[ 16.   8.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "4\n",
      "[[ 16.   8.   0.]\n",
      " [  8.   2.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "5\n",
      "[[ 16.   8.   0.]\n",
      " [  8.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "6\n",
      "[[ 32.   8.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "7\n",
      "[[ 64.   8.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "8\n",
      "[[ 64.   8.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "9\n",
      "[[ 64.   8.   0.]\n",
      " [  8.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "10\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "11\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   0.]\n",
      " [ 16.   4.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "12\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   0.]\n",
      " [ 32.   4.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "13\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   0.]\n",
      " [ 32.   4.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "14\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   0.]\n",
      " [ 32.   4.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "15\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   0.]\n",
      " [ 32.   8.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "16\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   0.]\n",
      " [ 32.   8.   0.]\n",
      " [ 16.   2.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "17\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   0.]\n",
      " [ 32.   8.   0.]\n",
      " [ 16.   2.   0.]\n",
      " [ 32.  16.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "18\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   0.]\n",
      " [ 32.   8.   0.]\n",
      " [ 16.   2.   0.]\n",
      " [  0.  64.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "19\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   0.]\n",
      " [ 64.   8.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.  64.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "20\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   0.]\n",
      " [ 64.   8.   0.]\n",
      " [ 32.   2.   0.]\n",
      " [  0.  64.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "21\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   0.]\n",
      " [ 64.   8.   0.]\n",
      " [ 32.   2.   0.]\n",
      " [  4.  64.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "22\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   0.]\n",
      " [ 64.   8.   0.]\n",
      " [ 32.   2.   0.]\n",
      " [  4.  64.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "23\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   4.]\n",
      " [ 64.   8.   0.]\n",
      " [ 32.   2.   0.]\n",
      " [  4.  64.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "24\n",
      "[[ 64.   8.   2.]\n",
      " [  8.   2.   4.]\n",
      " [ 64.   8.   0.]\n",
      " [ 32.   2.   0.]\n",
      " [  4.  64.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [ 32.   0.   0.]]\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "def buscarmax(lista):\n",
    "    i=0\n",
    "    maxx=0\n",
    "    for x in range(len(lista)):\n",
    "        if (lista[x]>maxx):\n",
    "            maxx=lista[x]\n",
    "            i=x\n",
    "    print(i,maxx)\n",
    "    return i\n",
    "mejor= buscarmax(Genetic1.Evaluation)\n",
    "\n",
    "verjugar(Genetic1.Population[mejor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 256.0, 192.0, 64.0, 64.0, 128.0, 256.0, 128.0, 128.0, 512.0, 128.0, 96.0, 96.0, 256.0, 64.0, 64.0, 256.0, 128.0, 128.0, 128.0, 32.0, 32.0, 128.0, 256.0, 128.0, 192.0, 128.0, 128.0, 256.0, 64.0, 128.0, 128.0, 64.0, 128.0, 96.0, 256.0, 128.0, 128.0, 64.0, 128.0, 96.0, 128.0, 64.0, 128.0, 128.0, 128.0, 64.0, 256.0, 32.0, 64.0, 96.0, 256.0, 64.0, 64.0, 64.0, 256.0, 128.0, 64.0, 128.0, 64.0, 128.0, 128.0, 256.0, 128.0, 96.0, 64.0, 128.0, 64.0, 192.0, 128.0, 256.0, 256.0, 96.0, 192.0, 128.0, 128.0, 32.0, 192.0, 128.0, 64.0, 192.0, 128.0, 96.0, 192.0, 128.0, 64.0, 128.0, 128.0, 32.0, 128.0, 64.0, 128.0, 128.0, 256.0, 64.0, 128.0, 64.0, 256.0, 128.0, 128.0, 256.0, 64.0, 256.0, 128.0, 256.0, 64.0, 128.0, 192.0, 128.0, 128.0, 64.0, 128.0, 192.0, 192.0, 256.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 64.0, 128.0, 192.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 64.0, 32.0, 64.0, 128.0, 128.0, 64.0, 96.0, 256.0, 128.0, 96.0, 64.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 256.0, 128.0, 64.0, 128.0, 256.0, 128.0, 256.0, 128.0, 256.0, 128.0, 64.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 32.0, 128.0, 128.0, 192.0, 192.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 256.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 64.0, 256.0, 128.0, 128.0, 64.0, 128.0, 64.0, 64.0, 96.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 96.0, 64.0, 256.0, 128.0, 128.0, 256.0, 128.0, 128.0, 64.0, 64.0, 32.0, 128.0, 64.0, 128.0, 64.0, 64.0, 64.0, 128.0, 64.0, 128.0, 256.0, 64.0, 256.0, 128.0, 256.0, 64.0, 128.0, 256.0, 128.0, 128.0, 64.0, 64.0, 64.0, 128.0, 128.0, 64.0, 256.0, 128.0, 64.0, 128.0, 256.0, 96.0, 128.0, 256.0, 64.0, 64.0, 128.0, 64.0, 64.0, 256.0, 96.0, 128.0, 128.0, 96.0, 48.0, 128.0, 256.0, 256.0, 128.0, 256.0, 128.0, 256.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 96.0, 128.0, 64.0, 128.0, 256.0, 192.0, 256.0, 128.0, 64.0, 64.0, 64.0, 192.0, 64.0, 192.0, 64.0, 128.0, 512.0, 256.0, 128.0, 256.0, 128.0, 256.0, 128.0, 64.0, 128.0, 64.0, 96.0, 96.0, 128.0, 96.0, 32.0, 128.0, 96.0, 128.0, 128.0, 256.0, 128.0, 64.0, 256.0, 128.0, 64.0, 64.0, 128.0, 128.0, 48.0, 128.0, 96.0, 128.0, 128.0, 64.0, 256.0, 256.0, 256.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 96.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 64.0, 64.0, 64.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 32.0, 64.0, 256.0, 64.0, 384.0, 128.0, 128.0, 128.0, 64.0, 32.0, 128.0, 256.0, 96.0, 128.0, 256.0, 128.0, 64.0, 128.0, 64.0, 96.0, 128.0, 64.0, 256.0, 64.0, 32.0, 128.0, 64.0, 256.0, 128.0, 128.0, 128.0, 256.0, 64.0, 256.0, 32.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 64.0, 128.0, 64.0, 128.0, 256.0, 128.0, 256.0, 256.0, 128.0, 96.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 64.0, 64.0, 64.0, 128.0, 128.0, 256.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 64.0, 64.0, 128.0, 256.0, 128.0, 256.0, 256.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 256.0, 128.0, 128.0, 192.0, 64.0, 192.0, 256.0, 128.0, 128.0, 256.0, 64.0, 32.0, 128.0, 128.0, 192.0, 128.0, 256.0, 512.0, 128.0, 128.0, 128.0, 32.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 96.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 48.0, 256.0, 64.0, 64.0, 256.0, 128.0, 256.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 256.0, 64.0, 128.0, 128.0, 128.0, 128.0, 32.0, 256.0, 128.0, 64.0, 64.0, 256.0, 128.0, 64.0, 64.0, 32.0, 128.0, 192.0, 256.0, 128.0, 128.0, 64.0, 64.0, 96.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 256.0, 128.0, 64.0, 128.0, 96.0, 256.0, 128.0, 128.0, 64.0, 192.0, 128.0, 256.0, 128.0, 128.0, 64.0, 64.0, 128.0, 256.0, 64.0, 128.0, 64.0, 192.0, 192.0, 128.0, 256.0, 64.0, 128.0, 128.0, 256.0, 192.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 64.0, 256.0, 128.0, 128.0, 32.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 256.0, 64.0, 128.0, 128.0, 256.0, 64.0, 192.0, 128.0, 32.0, 64.0, 192.0, 256.0, 256.0, 256.0, 64.0, 256.0, 64.0, 256.0, 64.0, 64.0, 128.0, 64.0, 64.0, 128.0, 64.0, 128.0, 256.0, 128.0, 64.0, 128.0, 64.0, 128.0, 512.0, 256.0, 128.0, 128.0, 256.0, 64.0, 64.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 256.0, 64.0, 128.0, 256.0, 64.0, 256.0, 192.0, 256.0, 64.0, 64.0, 128.0, 128.0, 64.0, 192.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 192.0, 128.0, 128.0, 256.0, 64.0, 64.0, 256.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 192.0, 64.0, 128.0, 64.0, 64.0, 192.0, 256.0, 64.0, 256.0, 128.0, 64.0, 128.0, 64.0, 128.0, 64.0, 256.0, 128.0, 256.0, 64.0, 128.0, 32.0, 128.0, 128.0, 64.0, 256.0, 256.0, 64.0, 32.0, 128.0, 256.0, 64.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 96.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 512.0, 96.0, 128.0, 512.0, 256.0, 256.0, 128.0, 256.0, 64.0, 32.0, 128.0, 128.0, 128.0, 64.0, 64.0, 384.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 32.0, 256.0, 128.0, 256.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 96.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 512.0, 128.0, 128.0, 256.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 16.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 256.0, 128.0, 96.0, 256.0, 64.0, 64.0, 128.0, 32.0, 128.0, 64.0, 128.0, 64.0, 64.0, 64.0, 128.0, 128.0, 256.0, 128.0, 64.0, 192.0, 64.0, 128.0, 128.0, 128.0, 64.0, 64.0, 128.0, 96.0, 96.0, 128.0, 128.0, 128.0, 128.0, 192.0, 256.0, 256.0, 96.0, 128.0, 96.0, 64.0, 128.0, 64.0, 128.0, 64.0, 64.0, 128.0, 64.0, 128.0, 256.0, 64.0, 256.0, 64.0, 64.0, 128.0, 64.0, 128.0, 256.0, 64.0, 32.0, 256.0, 64.0, 128.0, 128.0, 128.0, 64.0, 64.0, 128.0, 192.0, 96.0, 128.0, 128.0, 32.0, 256.0, 128.0, 256.0, 128.0, 128.0, 128.0, 192.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 96.0, 128.0, 128.0, 128.0, 64.0, 256.0, 256.0, 128.0, 128.0, 128.0, 32.0, 256.0, 64.0, 192.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 96.0, 128.0, 64.0, 128.0, 128.0, 256.0, 256.0, 128.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 64.0, 128.0, 32.0, 128.0, 128.0, 256.0, 128.0, 192.0, 256.0, 64.0, 96.0, 256.0, 128.0, 128.0, 64.0, 64.0, 256.0, 64.0, 128.0, 128.0, 256.0, 128.0, 256.0, 64.0, 128.0, 256.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 256.0, 128.0, 256.0, 128.0, 48.0, 128.0, 128.0, 96.0, 128.0, 128.0, 64.0, 128.0, 256.0, 128.0, 256.0, 128.0, 128.0, 128.0, 32.0, 128.0, 64.0, 256.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 64.0, 256.0, 128.0, 256.0, 128.0, 128.0, 96.0, 128.0, 128.0, 128.0, 64.0, 192.0, 64.0, 128.0, 128.0]\n"
     ]
    }
   ],
   "source": [
    "def Evaluador1(indv):\n",
    "    game= Game(3,7)\n",
    "    acapa1=[]\n",
    "    acapa2=[]\n",
    "    for x in range(28):\n",
    "        if(x<25):\n",
    "            acapa1.append(indv[x])\n",
    "        else:\n",
    "            acapa2.append(indv[x])\n",
    "    Capa1= Capa()\n",
    "    Capa2=Capa()\n",
    "    Capa1.setperceptrones(acapa1)\n",
    "    Capa2.setperceptrones(acapa2)\n",
    "    red1= Red_Neuronal()\n",
    "    red1.setcapinicial(Capa1) #Capa incial.\n",
    "    red1.setcapfinal(Capa2) #Capa final\n",
    "    red1.enlazar()\n",
    "    mov=0\n",
    "    while(game.end==0):\n",
    "        valor= choice([2.0,4.0,8.0,16.0,32.0])\n",
    "        entrada=[]\n",
    "        entrada.append(valor)\n",
    "        for fila in game.mesa:\n",
    "            for celda in fila:\n",
    "                entrada.append(celda)\n",
    "        red1.capinicial.getinput(normalizar(entrada))\n",
    "        red1.capinicial.Feeding()\n",
    "        \n",
    "        outp=red1.capfinal.output\n",
    "        i=0\n",
    "        maxx=0\n",
    "        i2=0\n",
    "        for xot in outp:\n",
    "            if(maxx<=xot):\n",
    "                i2=i\n",
    "                maxx=xot\n",
    "            i=i+1\n",
    "        x= game.movimiento(i2,valor)\n",
    "        game.verifica_multiplos(x,i2)\n",
    "        #print(game.mesa)\n",
    "        mov=mov+1\n",
    "    puntaje= MaxValoMesa(game.mesa)\n",
    "    return puntaje\n",
    "\n",
    "Genetic1.Fitness=Evaluador1\n",
    "Genetic1.Evaluate()\n",
    "print(Genetic1.Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128.0, 128.0, 128.0, 128.0, 256.0, 96.0, 128.0, 128.0, 128.0, 96.0, 128.0, 128.0, 128.0, 128.0, 256.0, 256.0, 256.0, 256.0, 64.0, 256.0, 64.0, 128.0, 256.0, 64.0, 32.0, 128.0, 256.0, 256.0, 128.0, 256.0, 64.0, 192.0, 64.0, 192.0, 128.0, 192.0, 32.0, 64.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 64.0, 64.0, 192.0, 64.0, 96.0, 64.0, 64.0, 256.0, 64.0, 96.0, 64.0, 128.0, 128.0, 128.0, 128.0, 256.0, 256.0, 128.0, 128.0, 192.0, 128.0, 256.0, 256.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 64.0, 64.0, 256.0, 96.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 32.0, 128.0, 128.0, 96.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 256.0, 64.0, 64.0, 128.0, 256.0, 128.0, 192.0, 128.0, 96.0, 64.0, 256.0, 64.0, 128.0, 128.0, 128.0, 128.0, 192.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 256.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 96.0, 256.0, 128.0, 96.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 64.0, 48.0, 128.0, 128.0, 128.0, 256.0, 64.0, 128.0, 256.0, 128.0, 128.0, 32.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 64.0, 256.0, 128.0, 128.0, 256.0, 64.0, 128.0, 128.0, 48.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 192.0, 192.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 256.0, 128.0, 64.0, 64.0, 64.0, 128.0, 64.0, 128.0, 64.0, 128.0, 128.0, 96.0, 128.0, 128.0, 256.0, 128.0, 128.0, 64.0, 128.0, 64.0, 96.0, 256.0, 128.0, 128.0, 128.0, 128.0, 64.0, 64.0, 128.0, 128.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 192.0, 128.0, 128.0, 128.0, 192.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 48.0, 64.0, 256.0, 64.0, 128.0, 128.0, 64.0, 128.0, 96.0, 128.0, 128.0, 32.0, 256.0, 128.0, 384.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 64.0, 256.0, 64.0, 256.0, 32.0, 64.0, 64.0, 256.0, 128.0, 64.0, 64.0, 128.0, 64.0, 256.0, 128.0, 192.0, 256.0, 32.0, 256.0, 64.0, 256.0, 128.0, 256.0, 96.0, 128.0, 256.0, 64.0, 64.0, 128.0, 256.0, 64.0, 128.0, 96.0, 128.0, 64.0, 128.0, 128.0, 192.0, 96.0, 64.0, 32.0, 64.0, 64.0, 96.0, 64.0, 64.0, 64.0, 256.0, 256.0, 128.0, 128.0, 128.0, 64.0, 256.0, 128.0, 64.0, 128.0, 256.0, 128.0, 128.0, 64.0, 256.0, 128.0, 256.0, 256.0, 192.0, 256.0, 64.0, 128.0, 128.0, 128.0, 32.0, 128.0, 256.0, 256.0, 256.0, 256.0, 128.0, 128.0, 64.0, 128.0, 96.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 64.0, 128.0, 32.0, 256.0, 256.0, 128.0, 256.0, 64.0, 128.0, 256.0, 128.0, 96.0, 128.0, 256.0, 128.0, 128.0, 64.0, 32.0, 64.0, 256.0, 128.0, 96.0, 128.0, 256.0, 128.0, 64.0, 128.0, 96.0, 128.0, 64.0, 64.0, 128.0, 128.0, 64.0, 128.0, 256.0, 96.0, 64.0, 32.0, 64.0, 128.0, 64.0, 64.0, 128.0, 64.0, 128.0, 128.0, 192.0, 64.0, 96.0, 128.0, 128.0, 128.0, 128.0, 96.0, 128.0, 128.0, 128.0, 128.0, 64.0, 192.0, 128.0, 96.0, 96.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 64.0, 96.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 96.0, 128.0, 128.0, 128.0, 192.0, 128.0, 128.0, 256.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 64.0, 256.0, 64.0, 256.0, 128.0, 128.0, 64.0, 128.0, 64.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 64.0, 256.0, 128.0, 256.0, 256.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 64.0, 64.0, 128.0, 256.0, 128.0, 64.0, 256.0, 64.0, 256.0, 128.0, 64.0, 128.0, 64.0, 128.0, 128.0, 256.0, 64.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 48.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 64.0, 128.0, 64.0, 64.0, 256.0, 64.0, 128.0, 128.0, 128.0, 64.0, 256.0, 128.0, 256.0, 256.0, 128.0, 128.0, 64.0, 128.0, 64.0, 32.0, 128.0, 64.0, 64.0, 96.0, 128.0, 256.0, 256.0, 128.0, 128.0, 64.0, 128.0, 192.0, 128.0, 128.0, 96.0, 64.0, 64.0, 128.0, 128.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 48.0, 32.0, 64.0, 32.0, 256.0, 64.0, 64.0, 128.0, 128.0, 256.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 64.0, 128.0, 128.0, 32.0, 128.0, 128.0, 256.0, 128.0, 64.0, 64.0, 96.0, 64.0, 64.0, 128.0, 128.0, 128.0, 64.0, 128.0, 64.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 192.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 256.0, 96.0, 128.0, 96.0, 64.0, 64.0, 96.0, 128.0, 32.0, 64.0, 256.0, 64.0, 256.0, 64.0, 256.0, 128.0, 128.0, 256.0, 128.0, 64.0, 256.0, 64.0, 128.0, 128.0, 64.0, 64.0, 96.0, 128.0, 128.0, 256.0, 128.0, 32.0, 256.0, 128.0, 128.0, 128.0, 128.0, 256.0, 256.0, 128.0, 128.0, 128.0, 128.0, 96.0, 256.0, 128.0, 256.0, 64.0, 128.0, 192.0, 64.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 64.0, 32.0, 128.0, 128.0, 192.0, 128.0, 256.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 64.0, 128.0, 128.0, 32.0, 256.0, 128.0, 128.0, 256.0, 64.0, 256.0, 64.0, 128.0, 64.0, 96.0, 128.0, 256.0, 128.0, 128.0, 128.0, 64.0, 64.0, 64.0, 256.0, 64.0, 128.0, 256.0, 256.0, 128.0, 256.0, 96.0, 128.0, 64.0, 64.0, 128.0, 128.0, 64.0, 128.0, 64.0, 128.0, 256.0, 64.0, 128.0, 128.0, 32.0, 128.0, 128.0, 128.0, 96.0, 128.0, 64.0, 96.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 32.0, 128.0, 64.0, 64.0, 256.0, 64.0, 256.0, 64.0, 128.0, 128.0, 128.0, 96.0, 128.0, 64.0, 256.0, 256.0, 256.0, 128.0, 64.0, 64.0, 256.0, 128.0, 96.0, 128.0, 128.0, 64.0, 128.0, 64.0, 256.0, 192.0, 128.0, 256.0, 64.0, 128.0, 64.0, 256.0, 64.0, 128.0, 64.0, 128.0, 64.0, 288.0, 256.0, 64.0, 64.0, 256.0, 64.0, 128.0, 128.0, 128.0, 64.0, 96.0, 128.0, 64.0, 128.0, 128.0, 128.0, 256.0, 128.0, 64.0, 96.0, 64.0, 128.0, 32.0, 64.0, 96.0, 128.0, 128.0, 128.0, 128.0, 32.0, 64.0, 96.0, 64.0, 128.0, 128.0, 96.0, 128.0, 128.0, 128.0, 128.0, 32.0, 128.0, 64.0, 128.0, 192.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 192.0, 64.0, 96.0, 64.0, 128.0, 128.0, 96.0, 128.0, 192.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 64.0, 128.0, 96.0, 16.0, 128.0, 128.0, 256.0, 64.0, 64.0, 128.0, 256.0, 128.0, 256.0, 256.0, 128.0, 128.0, 128.0, 32.0, 64.0, 128.0, 256.0, 128.0, 128.0, 64.0, 128.0, 128.0, 256.0, 32.0, 64.0, 64.0, 256.0, 64.0, 128.0, 128.0, 128.0, 32.0, 96.0, 256.0, 128.0, 96.0, 128.0, 256.0, 96.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 64.0, 64.0, 128.0, 256.0, 128.0, 128.0, 96.0, 256.0, 256.0, 128.0, 64.0, 64.0, 64.0, 128.0, 96.0, 128.0, 128.0, 256.0, 64.0, 128.0, 128.0, 128.0, 96.0, 96.0, 192.0, 128.0, 64.0, 128.0, 128.0, 32.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 256.0, 256.0, 64.0, 256.0, 256.0, 64.0, 128.0, 64.0, 384.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 64.0, 64.0, 64.0, 96.0, 128.0, 64.0, 192.0, 64.0, 96.0, 128.0, 256.0, 128.0]\n"
     ]
    }
   ],
   "source": [
    "for x in range(200):\n",
    "    Genetic1.Reproduction()\n",
    "    Genetic1.Evaluate()\n",
    "print(Genetic1.Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278 384.0\n",
      "ss\n",
      "[[ 8.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "1\n",
      "[[ 16.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "2\n",
      "[[ 16.   0.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "3\n",
      "[[ 16.   0.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "4\n",
      "[[ 16.   0.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "5\n",
      "[[ 16.   4.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "6\n",
      "[[ 16.   4.   2.]\n",
      " [ 32.   0.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "7\n",
      "[[ 16.   4.   2.]\n",
      " [ 32.   0.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [ 64.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "8\n",
      "[[ 16.   4.   2.]\n",
      " [ 32.  16.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [ 64.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "9\n",
      "[[ 16.   4.   2.]\n",
      " [ 32.  16.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [ 64.   0.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "10\n",
      "[[ 16.   4.   2.]\n",
      " [ 32.  16.   0.]\n",
      " [ 16.   8.   0.]\n",
      " [ 64.   0.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "11\n",
      "[[ 16.   4.   2.]\n",
      " [ 32.  16.   8.]\n",
      " [ 16.   8.   0.]\n",
      " [ 64.   0.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "12\n",
      "[[ 16.   4.   2.]\n",
      " [ 32.  16.   8.]\n",
      " [ 16.   8.   4.]\n",
      " [ 64.   0.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "13\n",
      "[[ 16.   4.   2.]\n",
      " [ 32.  16.   8.]\n",
      " [ 16.   8.   4.]\n",
      " [ 64.  16.   0.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "14\n",
      "[[ 16.   4.   2.]\n",
      " [ 32.  16.   8.]\n",
      " [ 16.   8.   4.]\n",
      " [ 64.   0.  32.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "15\n",
      "[[ 16.   4.   2.]\n",
      " [ 32.  16.   8.]\n",
      " [ 16.   8.   4.]\n",
      " [ 64.  16.  32.]\n",
      " [ 32.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "16\n",
      "[[  16.    4.    2.]\n",
      " [  32.   16.    8.]\n",
      " [  16.    8.    4.]\n",
      " [   0.  128.   32.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "17\n",
      "[[  16.    4.    2.]\n",
      " [  32.   16.    8.]\n",
      " [  16.    8.    4.]\n",
      " [   8.  128.   32.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "18\n",
      "[[  16.    4.    2.]\n",
      " [  64.   16.    8.]\n",
      " [   0.    8.    4.]\n",
      " [   0.  128.   32.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "19\n",
      "[[  16.    4.    2.]\n",
      " [  64.   16.    8.]\n",
      " [   2.    8.    4.]\n",
      " [   0.  128.   32.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "20\n",
      "[[  16.    4.    2.]\n",
      " [  64.   16.    8.]\n",
      " [   4.    8.    4.]\n",
      " [   0.  128.   32.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "21\n",
      "[[  16.    4.    2.]\n",
      " [  64.   16.    8.]\n",
      " [   4.    8.    4.]\n",
      " [   2.  128.   32.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "22\n",
      "[[  16.    4.    2.]\n",
      " [  64.   16.    8.]\n",
      " [   4.    8.    4.]\n",
      " [   2.  128.   32.]\n",
      " [  32.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "23\n",
      "[[  16.    4.    2.]\n",
      " [  64.   16.    8.]\n",
      " [   4.    8.    4.]\n",
      " [   2.  128.   32.]\n",
      " [  64.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "24\n",
      "[[  16.    4.    2.]\n",
      " [  64.   16.    8.]\n",
      " [   4.    8.    4.]\n",
      " [   2.  128.   32.]\n",
      " [  64.    0.    0.]\n",
      " [   2.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "25\n",
      "[[  16.    4.    2.]\n",
      " [  64.   16.    8.]\n",
      " [   4.    8.    4.]\n",
      " [   2.  128.   32.]\n",
      " [  64.    0.    0.]\n",
      " [   2.    0.    0.]\n",
      " [   4.    0.    0.]]\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "def buscarmax(lista):\n",
    "    i=0\n",
    "    maxx=0\n",
    "    for x in range(len(lista)):\n",
    "        if (lista[x]>maxx):\n",
    "            maxx=lista[x]\n",
    "            i=x\n",
    "    print(i,maxx)\n",
    "    return i\n",
    "mejor= buscarmax(Genetic1.Evaluation)\n",
    "\n",
    "verjugar(Genetic1.Population[mejor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[960.0, 1728.0, 8960.0, 2016.0, 4224.0, 1664.0, 4736.0, 15104.0, 11264.0, 8448.0, 1216.0, 1472.0, 14592.0, 3840.0, 832.0, 1664.0, 2880.0, 3936.0, 960.0, 4736.0, 3712.0, 3200.0, 3712.0, 4224.0, 1728.0, 896.0, 10240.0, 8448.0, 2432.0, 1920.0, 4864.0, 3584.0, 2304.0, 1152.0, 1472.0, 2944.0, 9728.0, 928.0, 3648.0, 896.0, 4992.0, 896.0, 1728.0, 3200.0, 4480.0, 3200.0, 5504.0, 9216.0, 1472.0, 512.0, 1216.0, 3072.0, 864.0, 2304.0, 5120.0, 1216.0, 3200.0, 1088.0, 7680.0, 5120.0, 2048.0, 1984.0, 1792.0, 2048.0, 6400.0, 3584.0, 1536.0, 1472.0, 1984.0, 1472.0, 3360.0, 6912.0, 4608.0, 7680.0, 7424.0, 4736.0, 2688.0, 3072.0, 3840.0, 2176.0, 2688.0, 4352.0, 6144.0, 4864.0, 3584.0, 3968.0, 640.0, 3168.0, 224.0, 576.0, 2688.0, 8960.0, 3328.0, 6144.0, 3584.0, 2496.0, 4992.0, 11520.0, 1408.0, 1088.0, 8704.0, 3840.0, 1216.0, 3072.0, 4864.0, 6016.0, 2688.0, 10240.0, 4352.0, 3072.0, 4096.0, 1408.0, 3456.0, 1792.0, 12032.0, 4992.0, 3200.0, 6912.0, 3072.0, 4736.0, 2944.0, 5248.0, 3200.0, 1664.0, 9728.0, 5760.0, 12800.0, 3072.0, 3584.0, 10240.0, 1536.0, 2880.0, 3328.0, 8704.0, 3360.0, 3456.0, 3712.0, 2944.0, 3264.0, 8960.0, 3712.0, 2784.0, 4224.0, 9728.0, 6912.0, 960.0, 7680.0, 3712.0, 4096.0, 5888.0, 3584.0, 10240.0, 1152.0, 9984.0, 4608.0, 1792.0, 7168.0, 1920.0, 1920.0, 1728.0, 6656.0, 2016.0, 5248.0, 4224.0, 416.0, 2560.0, 7424.0, 5568.0, 2944.0, 4608.0, 2688.0, 3584.0, 4352.0, 10752.0, 56.0, 4224.0, 960.0, 9728.0, 3712.0, 1088.0, 9408.0, 2944.0, 6144.0, 4608.0, 3968.0, 11776.0, 1152.0, 3584.0, 1664.0, 1280.0, 11264.0, 5376.0, 3072.0, 3584.0, 4096.0, 8832.0, 17408.0, 11520.0, 1472.0, 4096.0, 896.0, 3840.0, 6144.0, 1344.0, 3712.0, 4608.0, 4992.0, 5760.0, 3840.0, 1024.0, 2560.0, 3584.0, 4736.0, 4736.0, 2944.0, 2816.0, 768.0, 1344.0, 5632.0, 1472.0, 3648.0, 384.0, 1408.0, 4352.0, 800.0, 4992.0, 16896.0, 5952.0, 8064.0, 15360.0, 336.0, 1664.0, 4096.0, 21504.0, 6656.0, 3456.0, 1088.0, 9984.0, 3584.0, 4224.0, 3456.0, 3456.0, 2432.0, 3328.0, 2112.0, 320.0, 2944.0, 2432.0, 2400.0, 11776.0, 1920.0, 2304.0, 3456.0, 11264.0, 1664.0, 3584.0, 3328.0, 10240.0, 1824.0, 2944.0, 11776.0, 4992.0, 4352.0, 4096.0, 3200.0, 1600.0, 1856.0, 7936.0, 1600.0, 1280.0, 4608.0, 14336.0, 5760.0, 8704.0, 1152.0, 1664.0, 4736.0, 3456.0, 2688.0, 1536.0, 9472.0, 3968.0, 9216.0, 10752.0, 7680.0, 2112.0, 6272.0, 1024.0, 4096.0, 3072.0, 3456.0, 1024.0, 9216.0, 2688.0, 4352.0, 12032.0, 1664.0, 4352.0, 13312.0, 14592.0, 1408.0, 2048.0, 5888.0, 5248.0, 3584.0, 1792.0, 11264.0, 1536.0, 1536.0, 1792.0, 3584.0, 3712.0, 1728.0, 6016.0, 4608.0, 1216.0, 3712.0, 1920.0, 10240.0, 1472.0, 12032.0, 2880.0, 11520.0, 11264.0, 12288.0, 4224.0, 1984.0, 3456.0, 1728.0, 2432.0, 2176.0, 3584.0, 1600.0, 4736.0, 9728.0, 3328.0, 4032.0, 3200.0, 2176.0, 3200.0, 4480.0, 1344.0, 5888.0, 3328.0, 6016.0, 3168.0, 3328.0, 4608.0, 1664.0, 4096.0, 2432.0, 1472.0, 9472.0, 3584.0, 13056.0, 2944.0, 640.0, 2944.0, 3840.0, 4224.0, 4224.0, 4096.0, 1600.0, 1216.0, 1600.0, 1344.0, 3968.0, 3328.0, 4352.0, 1920.0, 4352.0, 9984.0, 864.0, 2048.0, 3584.0, 1728.0, 4096.0, 1792.0, 8960.0, 2944.0, 1024.0, 3072.0, 2816.0, 1792.0, 1664.0, 3456.0, 7936.0, 1920.0, 3072.0, 3456.0, 2304.0, 3072.0, 896.0, 3584.0, 544.0, 3744.0, 9216.0, 3840.0, 2496.0, 6912.0, 5120.0, 4864.0, 5120.0, 2176.0, 4224.0, 2400.0, 3200.0, 2432.0, 6272.0, 3648.0, 5120.0, 8704.0, 4736.0, 4992.0, 1728.0, 896.0, 5632.0, 1152.0, 3456.0, 7168.0, 1216.0, 12032.0, 5120.0, 3328.0, 2688.0, 3168.0, 1728.0, 1024.0, 3072.0, 3584.0, 3584.0, 5760.0, 512.0, 2880.0, 4992.0, 1216.0, 1152.0, 2816.0, 3840.0, 1728.0, 5376.0, 10240.0, 10240.0, 672.0, 9472.0, 4736.0, 5120.0, 2016.0, 1664.0, 448.0, 4096.0, 864.0, 2304.0, 3840.0, 2176.0, 4096.0, 11776.0, 2432.0, 1792.0, 2560.0, 2816.0, 1280.0, 2944.0, 4608.0, 5504.0, 3840.0, 3968.0, 3712.0, 2304.0, 11520.0, 4480.0, 5504.0, 4224.0, 5376.0, 1280.0, 3072.0, 4736.0, 4096.0, 1792.0, 896.0, 2112.0, 3712.0, 3200.0, 4224.0, 9600.0, 4224.0, 1856.0, 3968.0, 3456.0, 3328.0, 608.0, 12288.0, 1152.0, 2016.0, 10752.0, 4480.0, 3712.0, 3456.0, 3968.0, 6144.0, 5120.0, 13312.0, 3712.0, 12288.0, 3840.0, 3200.0, 5504.0, 1472.0, 4096.0, 3072.0, 1984.0, 9728.0, 4736.0, 3584.0, 5120.0, 3712.0, 1216.0, 5120.0, 3584.0, 2592.0, 3840.0, 2048.0, 4224.0, 3712.0, 6912.0, 704.0, 4480.0, 3456.0, 1664.0, 1472.0, 4224.0, 2816.0, 5376.0, 5376.0, 3456.0, 2304.0, 9472.0, 9984.0, 4608.0, 3968.0, 1024.0, 15360.0, 6528.0, 3456.0, 4992.0, 2976.0, 8448.0, 5120.0, 8192.0, 1856.0, 2944.0, 14080.0, 3328.0, 5120.0, 1408.0, 1920.0, 5120.0, 37888.0, 4608.0, 1152.0, 4224.0, 1472.0, 10496.0, 11008.0, 1216.0, 1216.0, 4736.0, 1728.0, 3840.0, 6144.0, 4096.0, 3456.0, 2432.0, 4224.0, 3968.0, 1408.0, 3584.0, 3840.0, 1856.0, 3456.0, 4480.0, 4224.0, 2496.0, 1536.0, 8448.0, 4608.0, 2048.0, 3200.0, 288.0, 4352.0, 6784.0, 5120.0, 4480.0, 5248.0, 1216.0, 6144.0, 11776.0, 4608.0, 1856.0, 4352.0, 17408.0, 1536.0, 3328.0, 6528.0, 2944.0, 4736.0, 1600.0, 13056.0, 3584.0, 896.0, 384.0, 768.0, 6336.0, 2944.0, 3456.0, 9728.0, 12032.0, 1536.0, 4992.0, 11264.0, 1280.0, 5760.0, 14848.0, 4224.0, 4736.0, 864.0, 2176.0, 5376.0, 2560.0, 14592.0, 1408.0, 8448.0, 6336.0, 4864.0, 11520.0, 3712.0, 12032.0, 3712.0, 2016.0, 4736.0, 1792.0, 1152.0, 1216.0, 11008.0, 1792.0, 4736.0, 3712.0, 3712.0, 1792.0, 4736.0, 4096.0, 4352.0, 1536.0, 4224.0, 2048.0, 2944.0, 256.0, 2944.0, 896.0, 6784.0, 8448.0, 5504.0, 3712.0, 4736.0, 3200.0, 1600.0, 640.0, 3840.0, 2048.0, 1600.0, 5888.0, 1600.0, 2816.0, 12288.0, 3712.0, 1216.0, 2560.0, 9216.0, 2816.0, 1152.0, 1216.0, 2944.0, 3200.0, 20736.0, 3840.0, 14592.0, 2176.0, 3072.0, 4736.0, 7936.0, 4352.0, 4032.0, 8704.0, 5248.0, 9472.0, 768.0, 2944.0, 3712.0, 4992.0, 1472.0, 4864.0, 3968.0, 4096.0, 11008.0, 2944.0, 8192.0, 5888.0, 11520.0, 960.0, 13568.0, 640.0, 3968.0, 3328.0, 1216.0, 11520.0, 13056.0, 2560.0, 3968.0, 1472.0, 4096.0, 8960.0, 2304.0, 3968.0, 4224.0, 8640.0, 4352.0, 1536.0, 7680.0, 704.0, 1728.0, 2560.0, 2944.0, 1280.0, 2944.0, 2368.0, 1536.0, 5120.0, 736.0, 5376.0, 4608.0, 4224.0, 2176.0, 2688.0, 4480.0, 6656.0, 6144.0, 1536.0, 1984.0, 1824.0, 5376.0, 11008.0, 3072.0, 4736.0, 1280.0, 1984.0, 3072.0, 2688.0, 2976.0, 3968.0, 4096.0, 3456.0, 9216.0, 1472.0, 576.0, 1472.0, 9472.0, 2944.0, 3072.0, 3968.0, 9728.0, 5632.0, 3200.0, 3840.0, 7936.0, 3328.0, 1056.0, 3968.0, 2816.0, 8960.0, 3968.0, 8448.0, 1664.0, 10240.0, 3712.0, 1280.0, 8960.0, 4736.0, 5120.0, 4224.0, 5376.0, 3072.0, 11264.0, 9408.0, 4608.0, 896.0, 5248.0, 4352.0, 9216.0, 2592.0, 2592.0, 5248.0, 960.0, 1280.0, 1152.0, 11776.0, 1472.0, 4480.0, 4480.0, 4480.0, 2432.0, 4608.0, 1216.0, 10496.0, 4096.0, 3552.0, 2048.0, 3200.0, 9472.0, 1024.0, 1408.0, 3584.0, 224.0, 3840.0, 4480.0, 2496.0, 3712.0, 4736.0, 832.0, 4480.0, 4352.0, 288.0, 7168.0, 7296.0, 3968.0, 3456.0, 1728.0, 3712.0, 768.0, 2592.0, 2432.0, 128.0, 2304.0, 3968.0, 3584.0, 4480.0, 1472.0, 1728.0, 3328.0, 1792.0, 2432.0, 5120.0, 3968.0, 1536.0, 2688.0, 3584.0, 2560.0, 8704.0, 14336.0, 2432.0, 1472.0, 12288.0, 5120.0, 1984.0, 14080.0, 3584.0, 3712.0, 2688.0, 2944.0, 13824.0, 384.0, 576.0, 1216.0, 1408.0, 2560.0, 2944.0, 5120.0, 10752.0, 4480.0, 3712.0, 2816.0, 512.0, 1536.0, 2176.0, 320.0, 1984.0, 1472.0, 13824.0, 5376.0, 256.0, 9216.0, 1664.0, 1664.0, 2816.0, 12544.0, 4224.0, 7424.0, 3840.0, 1280.0, 3584.0, 3712.0, 4992.0, 3456.0, 896.0, 4864.0, 1472.0, 33792.0, 448.0, 4480.0, 7680.0, 1984.0, 5952.0, 4128.0, 832.0, 4992.0, 4608.0, 3840.0, 4608.0, 3200.0, 960.0, 4480.0, 384.0, 1792.0, 5760.0, 1600.0, 12544.0, 4224.0, 9984.0, 5120.0, 3456.0, 4352.0, 1472.0, 7936.0, 4608.0, 6912.0, 3584.0, 4992.0, 1664.0, 4864.0, 11520.0, 4736.0, 1792.0, 1280.0, 8704.0, 3456.0, 11776.0, 1472.0, 3584.0, 2176.0, 2560.0, 4480.0, 2112.0, 4352.0, 11008.0, 5376.0, 14080.0, 4736.0, 3968.0, 2816.0, 1408.0, 4480.0, 4352.0, 5120.0, 2976.0, 2304.0, 3840.0, 1632.0, 3712.0, 2944.0, 3968.0, 5632.0, 7168.0, 2432.0, 3456.0, 960.0, 1024.0, 8448.0, 3840.0, 1664.0, 416.0, 11264.0, 4352.0, 2944.0, 5120.0, 4864.0, 1408.0, 640.0, 4608.0, 1344.0, 4096.0, 480.0, 1728.0, 3712.0, 4608.0, 704.0, 704.0, 2560.0, 9984.0, 4736.0, 1600.0, 1344.0]\n"
     ]
    }
   ],
   "source": [
    "def Evaluador2(indv):\n",
    "    game= Game(3,7)\n",
    "    acapa1=[]\n",
    "    acapa2=[]\n",
    "    for x in range(28):\n",
    "        if(x<25):\n",
    "            acapa1.append(indv[x])\n",
    "        else:\n",
    "            acapa2.append(indv[x])\n",
    "    Capa1= Capa()\n",
    "    Capa2=Capa()\n",
    "    Capa1.setperceptrones(acapa1)\n",
    "    Capa2.setperceptrones(acapa2)\n",
    "    red1= Red_Neuronal()\n",
    "    red1.setcapinicial(Capa1) #Capa incial.\n",
    "    red1.setcapfinal(Capa2) #Capa final\n",
    "    red1.enlazar()\n",
    "    mov=0\n",
    "    while(game.end==0):\n",
    "        valor= choice([2.0,4.0,8.0,16.0,32.0])\n",
    "        entrada=[]\n",
    "        entrada.append(valor)\n",
    "        for fila in game.mesa:\n",
    "            for celda in fila:\n",
    "                entrada.append(celda)\n",
    "        red1.capinicial.getinput(normalizar(entrada))\n",
    "        red1.capinicial.Feeding()\n",
    "        \n",
    "        outp=red1.capfinal.output\n",
    "        i=0\n",
    "        maxx=0\n",
    "        i2=0\n",
    "        for xot in outp:\n",
    "            if(maxx<=xot):\n",
    "                i2=i\n",
    "                maxx=xot\n",
    "            i=i+1\n",
    "        x= game.movimiento(i2,valor)\n",
    "        game.verifica_multiplos(x,i2)\n",
    "        #print(game.mesa)\n",
    "        mov=mov+1\n",
    "    puntaje= MaxValoMesa(game.mesa)\n",
    "    return puntaje*mov\n",
    "\n",
    "Genetic1.Fitness=Evaluador2\n",
    "Genetic1.Evaluate()\n",
    "print(Genetic1.Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3d4343231b58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mGenetic1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReproduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mGenetic1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGenetic1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvaluation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-bc3910988eb7>\u001b[0m in \u001b[0;36mEvaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mTournament_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-261e7c0f1b88>\u001b[0m in \u001b[0;36mEvaluador2\u001b[0;34m(indv)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mentrada\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mentrada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfila\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmesa\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcelda\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfila\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mentrada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcelda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in range(200):\n",
    "    Genetic1.Reproduction()\n",
    "    Genetic1.Evaluate()\n",
    "print(Genetic1.Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 256.0\n",
      "ss\n",
      "[[ 0.  2.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "1\n",
      "[[  0.   2.   0.]\n",
      " [  0.  32.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "2\n",
      "[[  0.   2.   0.]\n",
      " [  0.  64.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "3\n",
      "[[  0.   2.   0.]\n",
      " [  0.  64.   0.]\n",
      " [  0.  16.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "4\n",
      "[[  0.   2.  16.]\n",
      " [  0.  64.   0.]\n",
      " [  0.  16.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "5\n",
      "[[  0.   2.  16.]\n",
      " [  0.  64.   2.]\n",
      " [  0.  16.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "6\n",
      "[[  0.   2.  16.]\n",
      " [  0.  64.   4.]\n",
      " [  0.  16.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "7\n",
      "[[  0.   2.  16.]\n",
      " [  0.  64.   4.]\n",
      " [  0.   0.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "8\n",
      "[[  0.   2.  16.]\n",
      " [  0.  64.   4.]\n",
      " [  0.  16.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "9\n",
      "[[  0.   2.  16.]\n",
      " [  0.  64.   4.]\n",
      " [  0.  16.  32.]\n",
      " [  0.   0.   4.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "10\n",
      "[[  0.   2.  16.]\n",
      " [  0.  64.   4.]\n",
      " [  0.  16.  32.]\n",
      " [  0.  32.   4.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "11\n",
      "[[  0.   2.  16.]\n",
      " [  0.  64.   4.]\n",
      " [  0.  16.  32.]\n",
      " [  0.  32.   4.]\n",
      " [  0.  16.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "12\n",
      "[[  0.   2.  16.]\n",
      " [  0.  64.   4.]\n",
      " [  0.  16.  32.]\n",
      " [  0.  32.   4.]\n",
      " [  0.  16.   0.]\n",
      " [  0.  32.   0.]\n",
      " [  0.   0.   0.]]\n",
      "13\n",
      "[[  4.   2.  16.]\n",
      " [  0.  64.   4.]\n",
      " [  0.  16.  32.]\n",
      " [  0.  32.   4.]\n",
      " [  0.  16.   0.]\n",
      " [  0.  32.   0.]\n",
      " [  0.   0.   0.]]\n",
      "14\n",
      "[[  4.   2.  16.]\n",
      " [  2.  64.   4.]\n",
      " [  0.  16.  32.]\n",
      " [  0.  32.   4.]\n",
      " [  0.  16.   0.]\n",
      " [  0.  32.   0.]\n",
      " [  0.   0.   0.]]\n",
      "15\n",
      "[[  8.   2.  16.]\n",
      " [  0.  64.   4.]\n",
      " [  0.  16.  32.]\n",
      " [  0.  32.   4.]\n",
      " [  0.  16.   0.]\n",
      " [  0.  32.   0.]\n",
      " [  0.   0.   0.]]\n",
      "16\n",
      "[[  8.   2.  16.]\n",
      " [  4.  64.   4.]\n",
      " [  0.  16.  32.]\n",
      " [  0.  32.   4.]\n",
      " [  0.  16.   0.]\n",
      " [  0.  32.   0.]\n",
      " [  0.   0.   0.]]\n",
      "17\n",
      "[[  8.   2.  16.]\n",
      " [  4.  64.   8.]\n",
      " [  0.  96.   0.]\n",
      " [  0.  16.   0.]\n",
      " [  0.  32.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "18\n",
      "[[  8.   2.  16.]\n",
      " [  4.  64.   8.]\n",
      " [ 16.  96.   0.]\n",
      " [  0.  16.   0.]\n",
      " [  0.  32.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "19\n",
      "[[  8.   2.  16.]\n",
      " [  4.  64.   8.]\n",
      " [ 16.  96.   0.]\n",
      " [  2.  16.   0.]\n",
      " [  0.  32.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "20\n",
      "[[  8.   2.  16.]\n",
      " [  4.  64.   8.]\n",
      " [ 16.  96.  16.]\n",
      " [  2.  16.   0.]\n",
      " [  0.  32.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "21\n",
      "[[  8.   2.  16.]\n",
      " [  4.  64.   8.]\n",
      " [ 16.  96.  16.]\n",
      " [  2.  16.   0.]\n",
      " [ 16.  32.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "22\n",
      "[[  8.   2.  16.]\n",
      " [  4.  64.   8.]\n",
      " [ 16.  96.  16.]\n",
      " [  2.  16.   0.]\n",
      " [ 16.  32.   0.]\n",
      " [  8.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "23\n",
      "[[  8.   2.  16.]\n",
      " [  4.  64.   8.]\n",
      " [ 16.  96.  16.]\n",
      " [  2.  16.   0.]\n",
      " [ 16.  32.   0.]\n",
      " [  8.   0.   0.]\n",
      " [  2.   0.   0.]]\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "def buscarmax(lista):\n",
    "    i=0\n",
    "    maxx=0\n",
    "    for x in range(len(lista)):\n",
    "        if (lista[x]>maxx):\n",
    "            maxx=lista[x]\n",
    "            i=x\n",
    "    print(i,maxx)\n",
    "    return i\n",
    "mejor= buscarmax(Genetic1.Evaluation)\n",
    "\n",
    "verjugar(Genetic1.Population[mejor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Redes Iniciales--------Generaciones-------------Mejor Jugador--------------------MejorJuego\n",
    "       500                   100                      43                             32   en 10 juegos\n",
    "       500                   200                      50                             35   en 10 juegos  \n",
    "       500                   400                      59                             33   en 10 juegos \n",
    "       1000                  500                      85                             51   en 10 juegos \n",
    "       1000                  700                      77                             56   en 10 juegos \n",
    "       500                   400                     17 y 256                        33   en 10 juegos \n",
    "       1000              200 200                      58  y 384                      50  41        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
