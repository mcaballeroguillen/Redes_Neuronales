{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase del Juego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from random import randrange, choice\n",
    "class Game():\n",
    "    def __init__(self,colum,fil):\n",
    "        self.mesa= np.zeros( (fil,colum ) )  #Matríz que representa la mesa del juego\n",
    "        self.columnas=colum-1  # Número de columnas de la mesa\n",
    "        self.filas=fil-1 # Número de filas de la mesa\n",
    "        self.end=0 # Representa si el juego llegó a su fin.\n",
    "        self.mov=0 # Catidad de moviemintos \n",
    "        \n",
    "    def movimiento(self,colum,valor):  #Método que realizá un moviento en la mesa.\n",
    "        x=self.filas\n",
    "        y=colum\n",
    "        celda=self.mesa[x-1][y]\n",
    "        while(celda==0 and (x-1)>=0):\n",
    "            x=x-1\n",
    "            celda=self.mesa[x-1][y]\n",
    "        self.mesa[x][y]=valor\n",
    "        return x\n",
    "    \n",
    "    def verifica_multiplos(self,x,y):  #Método que verifica si al hacer un movimeinto, se puede reducir\n",
    "        valor= self.mesa[x][y]         #multiplos.\n",
    "        suma=valor\n",
    "        #Celda de arriba\n",
    "        if(x-1>=0):\n",
    "            if(self.mesa[x-1][y]==valor):\n",
    "                suma=suma+self.mesa[x-1][y]\n",
    "                self.mesa[x-1][y]=0.0\n",
    "        #Celda de Abajo\n",
    "        if(x+1<=self.filas):\n",
    "            if(self.mesa[x+1][y]==valor):\n",
    "                suma=suma+self.mesa[x+1][y]\n",
    "                self.mesa[x+1][y]=0.0\n",
    "        #Celda izquierda\n",
    "        if(y-1>=0):\n",
    "            if(self.mesa[x][y-1]==valor):\n",
    "                suma=suma+self.mesa[x][y-1]\n",
    "                self.mesa[x][y-1]=0.0\n",
    "        #Celda derecha\n",
    "        if(y+1<=self.columnas):\n",
    "            if(self.mesa[x][y+1]==valor):\n",
    "                suma=suma+self.mesa[x][y+1]\n",
    "                self.mesa[x][y+1]=0.0\n",
    "        if(valor!=suma):\n",
    "            self.mesa[x][y]=suma\n",
    "            self.verifica_multiplos(x,y)\n",
    "            \n",
    "        self.verificar_espacios()\n",
    "        \n",
    "    def verificar_espacios(self):        #Si despues de reducir multiplos quedan espació en blanco s\n",
    "        for x in range(self.filas+1):    #se moveran los valores de la matríz hacia arriba.\n",
    "            for y in range(self.columnas+1):\n",
    "                if(x+1<=self.filas):\n",
    "                    if(self.mesa[x][y]==0.0 and self.mesa[x+1][y]!=0.0):\n",
    "                        self.mesa[x][y]=self.mesa[x+1][y]\n",
    "                        self.mesa[x+1][y]=0.0\n",
    "                        self.verifica_multiplos(x,y)\n",
    "        self.verificar_end()\n",
    "    \n",
    "    def verificar_end(self):      # Verifica si el juego ya terminó, eso sucede caundo la última fila\n",
    "        for y in range(self.columnas+1):      #tiene algún valor.\n",
    "            if(self.mesa[self.filas][y]!=0.0):\n",
    "                self.end=1\n",
    "                \n",
    "    def run(self):   # Métdo para jugar\n",
    "        \n",
    "        while(self.end==0):\n",
    "            clear_output()\n",
    "            print(self.mesa) \n",
    "            valor= choice([2.0,4.0,8.0,16.0,32.0]) #Valor aleatorio de la pieza a jugar.\n",
    "            print(valor)\n",
    "            y=int(input()) #Esperar valor de la colomna donde se pondrá la nueva pieza. \n",
    "            x= self.movimiento(y,valor)  #Realizar movimiento\n",
    "            self.verifica_multiplos(x,y)  #Varificar multiplo y luego reducir espacios. \n",
    "        print(self.mesa)\n",
    "                \n",
    "       \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.   0.   0.]\n",
      " [  2.   0.   0.]\n",
      " [  4.   0.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [  2.   0.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "4.0\n",
      "0\n",
      "[[  8.   0.   0.]\n",
      " [  2.   0.   0.]\n",
      " [  4.   0.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [  2.   0.   0.]\n",
      " [ 16.   0.   0.]\n",
      " [  4.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "game= Game(3,7) #Ingresar Filas y columnas \n",
    "game.run()   # A Jugar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Código de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "#\"\"\" Clase que representa la capa de un perceptron sigmoide\"\"\"\n",
    "class Perceptron: \n",
    "    def __init__(self):\n",
    "        self.pesos= [] # \"\"\"Arreglo donde se guardan los pesos\"\"\"\n",
    "        self.datos=[]  #\"\"\" Arreglo donde se guardan los inputs\"\"\"\n",
    "        self.b=0  #\"\"\"Este valor representa el bais\"\"\"\n",
    "        self.out=0 #\"\"\" Este valor represente el output del sigmoide\"\"\"\n",
    "        self.error=0 #\"\"\" El error \"\"\"\n",
    "        self.delta=0  #\"\"\" El delta\"\"\"\n",
    "        self.lr=0.1 #\"\"\" El learning rata\"\"\"\n",
    "        self.bout=0  # \"\"\"Este valor represente en binario el output, por si se necesita\"\"\"\n",
    "    \n",
    "   # \"\"\" Método para agregar el learning rate\"\"\"\n",
    "    def agregarlr(self,valor):\n",
    "        self.lr=valor\n",
    "    #\"\"\" Agregar pesos\"\"\"\n",
    "    def agregarpeso(self,peso):\n",
    "        self.pesos.append(peso)\n",
    "    #\"\"\" Agregar los inputs\"\"\"    \n",
    "    def agregardato(self,dato):\n",
    "        self.datos.append(dato)\n",
    "    #\"\"\" Agregar bais\"\"\"    \n",
    "    def agregarbais(self,bais):\n",
    "        self.b=bais\n",
    "     #\"\"\"Agregar erro, este se utiliza si este perectron está en la última capa \"\"\"\"\n",
    "      #   \"\"\"ya que aquí el erro es la resta del output con el output esperado \"\"\"   \n",
    "    def agregarerror(self,valor):\n",
    "        self.error=valor\n",
    "   # \"\"\" Calcular el output del sigmoide, ya debe estar ingresados lo datos y los pesos\"\"\"\n",
    "    def run(self):\n",
    "        ps=np.array(self.pesos)\n",
    "        dt=np.array(self.datos)\n",
    "        x= ps*dt\n",
    "        suma=x.sum()\n",
    "        exponente = -1*(suma+self.b)\n",
    "        denominador = 1 + np.exp(exponente)\n",
    "        self.out=1/denominador\n",
    "        if self.out>=0.5: #\"\"\"Criterio para calcular el output binario\"\"\"\n",
    "            self.bout=1\n",
    "        else:\n",
    "            self.bout=0\n",
    "    #\"\"\"Agregar datos\"\"\"\n",
    "    def agregardatos(self,dats):\n",
    "        self.datos=dats\n",
    "     #\"\"\"Vaciar datos\"\"\"   \n",
    "    def vaciardatos(self):\n",
    "        self.datos=[]\n",
    "        \n",
    "    #\"\"\"Calcular error, ingresando los delta de la capa siguiente\"\"\"\n",
    "    def calcularerror(self,deltasnextcapa,pesosnextcapa):\n",
    "        ps=np.array(pesosnextcapa)\n",
    "        delt=np.array(deltasnextcapa)\n",
    "        \n",
    "        mult=ps*delt\n",
    "        self.error=mult.sum()\n",
    "    #\"\"\"Calcular del delta\"\"\"    \n",
    "    def calculardelta(self):\n",
    "        self.delta=self.error*(self.out*(1-self.out))\n",
    "    \n",
    "    #Despues de tener el delta se realiza el ajuste de los pesos, este se usa\n",
    "    #para el paso 3 de la backpropagation. \n",
    "    def ajustarpesos(self):\n",
    "        nuevospesos=[]\n",
    "        x=0\n",
    "        for peso in self.pesos:\n",
    "            nuevospesos.append(peso+(self.lr*self.delta*self.datos[x]))\n",
    "            x=x+1\n",
    "        self.pesos=nuevospesos\n",
    "        self.b=self.b + self.lr*self.delta    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Capa:\n",
    "    #\"\"\"Clase que representa una capa de red neuronal\"\"\"\n",
    "    def __init__(self):\n",
    "        self.perceptrones=[] #\"\"\"Arreglo con los pereceptrones\"\"\"\n",
    "        self.input=[] #\"\"\"Inputs que se le pasaran a  los pereceptrones \"\"\"\n",
    "        self.output=[] # \"\"\"Outputs que regresaran los perceptrones\"\"\"\n",
    "        self.deltas=[]  #\"\"\"Deltas de cada uno de los perceptrones \"\"\"\n",
    "        self.siguientecapa = None # \"\"\"Siguiente capa\"\"\"\n",
    "        self.anteriorcapa =None  # \"\"\"Capa anterior\"\"\"\n",
    "        self.boutput=[]\n",
    "        self.pesos=[]  #Arreglo que guarda los pesos de cada perceptron, arreglo de arreglos\n",
    "    def getnextcapa(self, capa):\n",
    "        self.siguientecapa = capa\n",
    "    \n",
    "    def getpreviouscapa(self,capa):\n",
    "        self.anteriorcapa = capa\n",
    "   # \"\"\"Agregar inputs\"\"\"\n",
    "    def getinput(self,datos):\n",
    "        self.input=datos\n",
    "    # Agregar perceptron individual\n",
    "    def getperceptron(self, perceptron):\n",
    "        self.perceptrones.append(perceptron)\n",
    "        self.pesos.append(perceptron.pesos)\n",
    "   \n",
    "    #Cargar los pesos de los perceptrones\n",
    "    def cargarpesos(self):\n",
    "        pesos=[]\n",
    "        for per in self.perceptrones:\n",
    "            pesos.append(per.pesos)\n",
    "        self.pesos=pesos\n",
    "    # Agregar perceptrones arreglo     \n",
    "    def setperceptrones(self, arreglo):\n",
    "        self.perceptrones=arreglo\n",
    "        pesos=[]\n",
    "        for per in arreglo:\n",
    "            pesos.append(per.pesos)\n",
    "        self.pesos=pesos\n",
    "        \n",
    "   #\"\"\"Recorrido para calcular output \"\"\"\n",
    "    def Feeding(self):\n",
    "        self.output=[]\n",
    "        self.boutput=[]\n",
    "        for perc in self.perceptrones: #\"\"\"Cada perceptron recibe los datos y su respuestas son cargadas al outputs\"\"\"\n",
    "            perc.agregardatos(self.input)\n",
    "            perc.run()\n",
    "            self.output.append(perc.out)\n",
    "            self.boutput.append(perc.bout)\n",
    "        if self.siguientecapa != None: #\"\"\"Si no es la última capa, se pasá mi output como input de la siguiente capa\"\"\"\n",
    "            self.siguientecapa.getinput(self.output)\n",
    "            self.siguientecapa.Feeding()\n",
    "    \n",
    "   #Método backprogation para la última cap, recibe un arreglo con los output esperados\n",
    "\n",
    "    def backpropagation(self, expectoutput):\n",
    "        self.deltas=[] #Vaciamo los deltas\n",
    "        x=0\n",
    "        for perc in self.perceptrones:\n",
    "            perc.agregarerror(expectoutput[x]-perc.out)# \"\"\"Cada pereceptron recibe su error\"\"\"\n",
    "            perc.calculardelta()#\"\"\"Cada perceptron calcula su delta\"\"\"\n",
    "            self.deltas.append(perc.delta) #\"\"\"Se agregan a los delta de la capaa \"\"\"\n",
    "            x=x+1\n",
    "        self.anteriorcapa.backpropagation1(self.deltas,self.pesos) #Backpropagation para otreas capas. \n",
    "        #Despues se propaga el error, comenzamos a ajustar los pesos.\n",
    "        for perc in self.perceptrones:\n",
    "            perc.ajustarpesos()\n",
    "        self.cargarpesos()\n",
    "    #Métod backpropagation para capas distan a las final,recibe los deltas y pesos de la sigueinte capa.     \n",
    "    def backpropagation1(self,deltas,pesos):\n",
    "        self.deltas=[] #Vaciamos los deltas\n",
    "        x=0\n",
    "        for perc in self.perceptrones:\n",
    "            pecorres=[] #Pesos correspondientes para un perceptron específico\n",
    "            for pp in pesos: #pp es un arreglo con los pesos de un perceptron de la capa siguiente\n",
    "                pecorres=pp[x]     #Sacamos nuestro peso correspondiente de ese perceotron\n",
    "            perc.calcularerror(deltas,pecorres) # El perecptron calcula el erro\n",
    "            perc.calculardelta() # El perceptron calcula el delta.\n",
    "            self.deltas.append(perc.delta) #Agregamos el delta al arreglo de la capa\n",
    "            x=x+1\n",
    "        if(self.anteriorcapa==None): #Si es la primera capa, detemos la propagación\n",
    "            for perc in self.perceptrones: \n",
    "                perc.ajustarpesos() # Paso 3 de el backpropagation, ajustamos los pesos\n",
    "            self.cargarpesos() #Cargamos lo pesos al arreglo de la capa\n",
    "        else:\n",
    "            self.anteriorcapa.backpropagation1(self.deltas,self.pesos) #Seguimos con la propagación\n",
    "            for perc in self.perceptrones:\n",
    "                perc.ajustarpesos() #Al terminar la propagación ajustamos los pesos.\n",
    "            self.cargarpesos()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Fabrica:\n",
    "    def __init__(self):\n",
    "        self.lr=0.1 #learning range con el que se crearn los perceptrones\n",
    "        self.bais=-1 #bais con el que se crearan los peceptrones\n",
    "        \n",
    "    def getlr(self,valor):\n",
    "        self.lr=valor\n",
    "        \n",
    "    def getbais(self,valor):\n",
    "        self.bais=valor\n",
    "    #Método que crea un perecpetron con cantidad especifica de pesos   \n",
    "    def crearPerceptron(self,cantPesos):\n",
    "        per= Perceptron()\n",
    "        for x in range(cantPesos):\n",
    "            per.agregarpeso(uniform(-2,2))\n",
    "        per.agregarlr(self.lr)\n",
    "        per.agregarbais(self.bais)\n",
    "        return per\n",
    "    #Método que crea una capa con una cantidad especifica de perceptrones y pesos.\n",
    "    def crearCapa(self, cantPer, cantPesos):\n",
    "        cap= Capa()\n",
    "        for x in range(cantPer):\n",
    "            cap.getperceptron(self.crearPerceptron(cantPesos))\n",
    "        return cap    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Red_Neuronal:\n",
    "    def __init__(self):\n",
    "        self.capinicial=None #Capa inicial \n",
    "        self.capintemedias=[] #Arreglo donde se guardaran las capas intemedias, deben ser ingresadas en orden.\n",
    "        self.capfinal=None\n",
    "    #Se agrega la capa incial a la red neuronal, se asume que esta tiene los perceptrones y pesos correctos.\n",
    "    def setcapinicial(self,capa):\n",
    "        self.capinicial=capa\n",
    "    #Agregar capa final.\n",
    "    def setcapfinal(self, capa):\n",
    "        self.capfinal= capa\n",
    "    #Agregar una capa intemedia, se debe agregar en orden\n",
    "    def setcapaintermedia(self, capa):\n",
    "        self.capintemedias.append(capa)\n",
    "    #Método para que cada capa reciba su capa anterior y su capa siguiente    \n",
    "    def enlazar(self):\n",
    "        if len(self.capintemedias)==0: #Si no hay capas intermedias\n",
    "            self.capinicial.getnextcapa(self.capfinal)   #Se enlazan la primera con la última\n",
    "            self.capfinal.getpreviouscapa(self.capinicial)\n",
    "        else:  #Si hay capas intemedias\n",
    "            x=0\n",
    "            self.capinicial.getnextcapa(self.capintemedias[x]) #Se enlaza la capa inicial, con la primera capa del arreglo\n",
    "            while x<(len(self.capintemedias)-1):\n",
    "                self.capintemedias[x].getnextcapa(self.capintemedias[x+1]) #Se enlaza cada capa, con su siguiente\n",
    "                x=x+1\n",
    "            x=len(self.capintemedias)-1\n",
    "            while x>0:\n",
    "                self.capintemedias[x].getpreviouscapa(self.capintemedias[x-1])#Se enlaza cada capa, con la anterior\n",
    "                x=x-1\n",
    "            x=len(self.capintemedias)-1\n",
    "            self.capfinal.getpreviouscapa(self.capintemedias[x]) #Se enlza la  útima capa del arrglo, con la capa final\n",
    "            self.capintemedias[x].getnextcapa(self.capfinal)\n",
    "    \n",
    "    def comparador(self,conjunto1,conjunto2):\n",
    "        x=1\n",
    "        i=0\n",
    "        for z in conjunto1:\n",
    "            if(z!=conjunto2[i]):\n",
    "                x=0\n",
    "                return x\n",
    "            i=i+1\n",
    "        return x\n",
    "    \n",
    "    #Método para entrenar, devuelve los errores\n",
    "    def entrenar(self,settrain,num, settest):\n",
    "        inputrain=settrain[0]\n",
    "        outputtrain=settrain[1]\n",
    "        inputtest=settest[0]\n",
    "        outputtest=settest[1]\n",
    "        intentos=[]\n",
    "        resultados=[]\n",
    "        \n",
    "        for x in range(num):\n",
    "            i=0\n",
    "            for tupla in inputrain:\n",
    "                self.capinicial.getinput(tupla)\n",
    "                self.capinicial.Feeding()\n",
    "                self.capfinal.backpropagation(outputtrain[i])\n",
    "                i=i+1\n",
    "            i=0\n",
    "            errores=0\n",
    "            for tupla in inputtest:\n",
    "                self.capinicial.getinput(tupla)\n",
    "                self.capinicial.Feeding()\n",
    "                if self.comparador(self.capfinal.boutput,outputtest[i])==0:\n",
    "                    errores=errores+1\n",
    "                i=i+1\n",
    "            resultados.append(errores)\n",
    "            intentos.append(x+1)\n",
    "        return [intentos,resultados]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código Algóritmo Genético "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random, randrange \n",
    "class Genetic_Algoritmo:\n",
    "    def __init__(self):\n",
    "        self.Mutation_Rate=0.01\n",
    "        self.Genes=0\n",
    "        self.Population=[]\n",
    "        self.Evaluation=[]\n",
    "        self.Generador=None\n",
    "        self.Fitness=None\n",
    "        self.Selecction=[]\n",
    "    \n",
    "    def genera_popinicial(self, num):\n",
    "        for x in range(num):\n",
    "            indiv=[]\n",
    "            for w in range(self.Genes):\n",
    "                indiv.append(self.Generador(w))\n",
    "            self.Population.append(indiv)\n",
    "    \n",
    "    def Evaluate(self):\n",
    "        self.Evaluation=[]\n",
    "        for x in range(len(self.Population)):\n",
    "            self.Evaluation.append(self.Fitness(self.Population[x]))\n",
    "    \n",
    "    def Tournament_selection(self,k):\n",
    "        ind=-1;\n",
    "        for x in range(k):\n",
    "            r= randrange(len(self.Population)) \n",
    "            if(ind==-1 or self.Evaluation[r]>self.Evaluation[ind]):\n",
    "                ind=r\n",
    "        self.Selecction.append(self.Population[ind])\n",
    "        \n",
    "    def Reproduction(self):\n",
    "        largo=len(self.Population)\n",
    "        newPop=[]\n",
    "        self.Selecction=[]\n",
    "        for x in range(2*largo):\n",
    "            self.Tournament_selection(5)\n",
    "        for x in range(largo):\n",
    "            newindv=[]\n",
    "            indiv1= self.Selecction[x]\n",
    "            indiv2= self.Selecction[x+largo]\n",
    "            point_mixing= randrange(self.Genes)\n",
    "            for x in range(self.Genes):\n",
    "                if(x>point_mixing):\n",
    "                    newindv.append(indiv2[x])\n",
    "                else:\n",
    "                    newindv.append(indiv1[x])\n",
    "            i=0\n",
    "            for gen in newindv:\n",
    "                rand= random()\n",
    "                if rand<self.Mutation_Rate:\n",
    "                    newgen=self.Generador(i) #Aquí este el cambio\n",
    "                    newindv[i]=newgen\n",
    "                i=i+1\n",
    "            newPop.append(newindv)\n",
    "        self.Population=newPop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Necesarias para la Nueroevolución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randrange, choice,uniform\n",
    "game= Game(3,7)\n",
    "fabri= Fabrica()\n",
    "def normalizar(arreglo):  #Clase que Normaliza un arreglo.\n",
    "    salida=[]\n",
    "    for x in arreglo:\n",
    "        salida.append(x/1024)\n",
    "    return salida\n",
    "\n",
    "def Generador(ind):   # Generador de Perceotrones, según índice. \n",
    "    if(ind<25):\n",
    "        return fabri.crearPerceptron(22)\n",
    "    else:\n",
    "        return fabri.crearPerceptron(25)\n",
    "    \n",
    "def MaxValoMesa(mesa):\n",
    "    maxx=0;\n",
    "    for fila in mesa:\n",
    "        for valor in fila:\n",
    "            if (valor>maxx):\n",
    "                maxx=valor\n",
    "    return maxx\n",
    "    \n",
    "def Evaluador(indv):  #Primer Fitnes, mayor cantidad de movimeinto. \n",
    "    game= Game(3,7)\n",
    "    acapa1=[]\n",
    "    acapa2=[]\n",
    "    for x in range(28):\n",
    "        if(x<25):\n",
    "            acapa1.append(indv[x])\n",
    "        else:\n",
    "            acapa2.append(indv[x])\n",
    "    Capa1= Capa()\n",
    "    Capa2=Capa()\n",
    "    Capa1.setperceptrones(acapa1)\n",
    "    Capa2.setperceptrones(acapa2)\n",
    "    red1= Red_Neuronal()\n",
    "    red1.setcapinicial(Capa1) #Capa incial.\n",
    "    red1.setcapfinal(Capa2) #Capa final\n",
    "    red1.enlazar()\n",
    "    mov=0\n",
    "    while(game.end==0):\n",
    "        valor= choice([2.0,4.0,8.0,16.0,32.0])\n",
    "        entrada=[]\n",
    "        entrada.append(valor)\n",
    "        for fila in game.mesa:\n",
    "            for celda in fila:\n",
    "                entrada.append(celda)\n",
    "        red1.capinicial.getinput(normalizar(entrada))\n",
    "        red1.capinicial.Feeding()\n",
    "        \n",
    "        outp=red1.capfinal.output\n",
    "        i=0\n",
    "        maxx=0\n",
    "        i2=0\n",
    "        for xot in outp:\n",
    "            if(maxx<=xot):\n",
    "                i2=i\n",
    "                maxx=xot\n",
    "            i=i+1\n",
    "        x= game.movimiento(i2,valor)\n",
    "        game.verifica_multiplos(x,i2)\n",
    "        #print(game.mesa)\n",
    "        mov=mov+1\n",
    "    return mov\n",
    "\n",
    "def verjugar(indv):  # Este método se utilizó para ver jugar un individuo \n",
    "    game= Game(3,7)   #imprime todos los movimetos realiados. \n",
    "    print(\"ss\")\n",
    "    acapa1=[]\n",
    "    acapa2=[]\n",
    "    for x in range(28):\n",
    "        if(x<25):\n",
    "            acapa1.append(indv[x])\n",
    "        else:\n",
    "            acapa2.append(indv[x])\n",
    "    Capa1= Capa()\n",
    "    Capa2= Capa()\n",
    "    Capa1.setperceptrones(acapa1)\n",
    "    Capa2.setperceptrones(acapa2)\n",
    "    red1= Red_Neuronal()\n",
    "    red1.setcapinicial(Capa1) #Capa incial.\n",
    "    red1.setcapfinal(Capa2) #Capa final\n",
    "    red1.enlazar()\n",
    "    mov=0\n",
    "    while(game.end==0):\n",
    "        valor= choice([2.0,4.0,8.0,16.0,32.0])\n",
    "        entrada=[]\n",
    "        entrada.append(valor)\n",
    "        for fila in game.mesa:\n",
    "            for celda in fila:\n",
    "                entrada.append(celda)\n",
    "        red1.capinicial.getinput(normalizar(entrada))\n",
    "        red1.capinicial.Feeding()\n",
    "        \n",
    "        outp=red1.capfinal.output\n",
    "        i=0\n",
    "        maxx=0\n",
    "        i2=0\n",
    "        for xot in outp:\n",
    "            if(maxx<=xot):\n",
    "                i2=i\n",
    "                maxx=xot\n",
    "            i=i+1\n",
    "        x= game.movimiento(i2,valor)\n",
    "        game.verifica_multiplos(x,i2)\n",
    "        print(game.mesa)\n",
    "        mov=mov+1\n",
    "        print(mov)\n",
    "        \n",
    "Genetic1 = Genetic_Algoritmo()\n",
    "Genetic1.Fitness=Evaluador\n",
    "Genetic1.Generador=Generador\n",
    "Genetic1.Genes=28\n",
    "Genetic1.genera_popinicial(1000)\n",
    "Genetic1.Evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 7, 8, 8, 10, 12, 10, 8, 10, 8, 11, 8, 9, 8, 7, 9, 7, 9, 8, 10, 8, 10, 12, 9, 7, 8, 9, 9, 7, 7, 14, 10, 8, 8, 7, 9, 9, 11, 7, 10, 8, 7, 9, 11, 8, 8, 9, 8, 8, 8, 8, 11, 8, 8, 9, 7, 8, 7, 8, 8, 13, 15, 10, 10, 7, 7, 7, 10, 8, 8, 8, 8, 10, 13, 7, 14, 10, 8, 10, 7, 9, 8, 7, 8, 8, 10, 7, 8, 9, 9, 7, 10, 8, 13, 8, 8, 9, 10, 12, 8, 9, 9, 9, 8, 10, 10, 8, 14, 9, 10, 10, 7, 7, 7, 10, 7, 9, 7, 7, 9, 9, 9, 8, 11, 11, 11, 8, 8, 8, 12, 7, 9, 8, 11, 12, 10, 8, 8, 10, 13, 7, 9, 7, 7, 8, 9, 9, 8, 9, 7, 11, 14, 13, 7, 8, 8, 7, 8, 10, 11, 8, 7, 8, 8, 9, 7, 10, 7, 8, 7, 8, 8, 9, 7, 9, 8, 8, 9, 7, 7, 10, 11, 10, 9, 8, 10, 10, 9, 8, 12, 8, 10, 15, 7, 19, 9, 7, 7, 7, 8, 9, 8, 9, 7, 7, 12, 8, 7, 10, 7, 8, 9, 7, 7, 7, 9, 13, 7, 9, 10, 8, 11, 8, 8, 12, 10, 9, 7, 10, 7, 8, 10, 8, 7, 8, 7, 7, 8, 8, 7, 8, 8, 10, 11, 8, 11, 8, 8, 7, 8, 8, 8, 7, 8, 7, 7, 7, 7, 8, 7, 11, 7, 11, 8, 8, 8, 10, 11, 14, 7, 8, 8, 12, 8, 8, 10, 8, 8, 7, 7, 13, 9, 10, 7, 8, 11, 10, 8, 11, 8, 15, 7, 8, 7, 7, 8, 13, 8, 8, 8, 11, 12, 8, 8, 14, 7, 7, 11, 7, 9, 9, 10, 8, 8, 7, 8, 8, 13, 9, 10, 9, 7, 9, 7, 7, 8, 10, 9, 12, 8, 11, 8, 7, 10, 7, 7, 8, 9, 8, 8, 7, 7, 11, 8, 7, 8, 13, 11, 7, 7, 7, 8, 7, 13, 9, 8, 9, 8, 8, 11, 10, 7, 8, 7, 9, 8, 9, 11, 8, 8, 12, 7, 7, 11, 8, 7, 11, 11, 7, 10, 8, 15, 7, 9, 14, 7, 7, 7, 7, 9, 8, 9, 9, 11, 7, 9, 8, 7, 9, 7, 9, 8, 12, 14, 9, 12, 8, 11, 9, 9, 8, 7, 7, 8, 7, 12, 7, 8, 10, 9, 10, 8, 10, 7, 8, 8, 8, 10, 9, 11, 8, 8, 9, 7, 8, 9, 7, 9, 11, 8, 16, 10, 9, 10, 9, 8, 7, 11, 9, 9, 8, 11, 9, 14, 8, 7, 14, 7, 8, 8, 8, 7, 9, 13, 9, 8, 7, 11, 11, 8, 10, 8, 7, 8, 10, 9, 7, 10, 7, 7, 7, 11, 9, 8, 7, 8, 8, 8, 9, 9, 7, 12, 9, 9, 8, 8, 9, 11, 7, 9, 7, 7, 8, 10, 7, 10, 13, 10, 8, 12, 13, 12, 8, 8, 8, 7, 8, 8, 9, 12, 9, 9, 8, 12, 10, 7, 9, 12, 12, 7, 7, 7, 10, 10, 11, 11, 7, 10, 8, 8, 8, 10, 10, 8, 16, 7, 9, 7, 10, 9, 11, 11, 7, 7, 7, 9, 7, 8, 7, 9, 12, 8, 11, 8, 7, 8, 9, 9, 9, 8, 9, 9, 9, 8, 11, 8, 8, 10, 12, 8, 9, 7, 7, 9, 7, 10, 7, 10, 8, 8, 10, 8, 8, 9, 11, 13, 7, 10, 8, 8, 7, 7, 8, 9, 7, 7, 7, 12, 9, 9, 11, 10, 8, 8, 7, 9, 13, 8, 7, 9, 8, 10, 9, 8, 7, 7, 10, 7, 14, 12, 8, 9, 8, 8, 10, 9, 9, 7, 10, 7, 9, 7, 7, 9, 9, 7, 13, 7, 7, 9, 7, 8, 9, 10, 7, 9, 8, 10, 8, 7, 7, 9, 8, 11, 7, 7, 8, 8, 9, 8, 7, 7, 9, 9, 14, 11, 8, 8, 10, 8, 7, 7, 9, 7, 7, 8, 11, 7, 8, 10, 11, 9, 7, 10, 10, 7, 8, 7, 11, 8, 9, 11, 15, 7, 7, 11, 7, 9, 8, 9, 7, 9, 9, 12, 7, 11, 8, 8, 8, 11, 8, 10, 9, 7, 9, 7, 11, 7, 14, 8, 8, 9, 12, 10, 7, 12, 11, 7, 8, 7, 11, 11, 8, 14, 10, 10, 7, 9, 8, 7, 7, 9, 9, 8, 9, 8, 11, 9, 10, 10, 7, 13, 7, 10, 7, 7, 7, 8, 8, 10, 8, 9, 7, 8, 10, 8, 8, 7, 9, 8, 9, 7, 9, 10, 8, 8, 12, 9, 7, 7, 8, 14, 9, 7, 14, 8, 7, 10, 7, 7, 13, 8, 9, 8, 12, 8, 9, 11, 7, 10, 7, 9, 7, 13, 16, 7, 8, 8, 13, 10, 11, 13, 7, 12, 7, 7, 7, 8, 7, 8, 10, 7, 9, 10, 11, 16, 9, 12, 8, 7, 11, 8, 7, 9, 7, 7, 7, 12, 7, 10, 7, 10, 9, 10, 12, 8, 7, 8, 7, 10, 8, 7, 8, 7, 8, 8, 11, 10, 7, 7, 10, 9, 7, 7, 8, 10, 7, 8, 9, 8, 8, 9, 9, 8, 10, 8, 7, 10, 8, 9, 10, 12, 12, 8, 8, 8, 16, 11, 13, 9, 7, 8, 10, 7, 8, 9, 10, 10, 9, 8, 7, 7, 8, 7, 9, 9, 8, 8, 7, 8, 7, 7, 7, 7, 9, 8, 8, 8, 8, 9, 9, 11, 8, 9, 7, 9, 8, 8, 19, 10, 7, 8, 9, 9, 10, 10, 7, 9, 7, 10, 7, 15, 7, 9, 7, 8, 17, 9, 8, 8, 7, 13, 7, 8, 7, 9, 8, 7, 7, 7, 10, 7, 9, 8, 8, 9, 10, 8, 8, 8, 12, 9, 9, 7, 9, 9, 7, 10, 10, 10, 10, 7, 11, 12, 10, 8, 8, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "print(Genetic1.Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 32, 25, 18, 16, 26, 19, 17, 27, 26, 21, 25, 36, 14, 19, 43, 32, 16, 37, 24, 42, 24, 42, 48, 42, 31, 34, 12, 21, 27, 41, 32, 37, 17, 30, 28, 18, 29, 20, 16, 24, 21, 19, 56, 13, 34, 18, 49, 16, 28, 20, 29, 29, 12, 44, 44, 21, 27, 28, 38, 33, 37, 23, 23, 42, 38, 58, 27, 25, 37, 47, 43, 48, 45, 28, 32, 34, 30, 24, 31, 20, 24, 26, 19, 21, 46, 33, 24, 25, 24, 24, 34, 28, 36, 34, 27, 25, 34, 25, 30, 39, 46, 22, 37, 28, 36, 41, 37, 22, 12, 56, 41, 18, 26, 20, 24, 19, 38, 19, 16, 26, 32, 25, 23, 25, 13, 25, 35, 36, 26, 27, 27, 29, 17, 57, 38, 17, 16, 34, 33, 24, 27, 21, 21, 29, 29, 28, 46, 33, 33, 39, 28, 15, 23, 12, 28, 21, 28, 25, 21, 21, 29, 28, 31, 22, 38, 46, 29, 16, 23, 17, 35, 28, 31, 36, 28, 31, 23, 22, 20, 7, 28, 22, 37, 43, 8, 36, 26, 13, 42, 26, 26, 16, 33, 34, 19, 11, 24, 41, 28, 29, 52, 26, 24, 28, 23, 35, 27, 34, 26, 53, 20, 18, 50, 32, 21, 21, 35, 26, 29, 26, 35, 26, 24, 43, 34, 30, 20, 41, 16, 16, 15, 24, 24, 32, 34, 30, 35, 24, 31, 14, 15, 39, 22, 38, 50, 20, 23, 31, 40, 36, 39, 33, 21, 27, 32, 27, 27, 34, 22, 19, 20, 14, 27, 43, 10, 30, 25, 26, 34, 23, 41, 21, 18, 22, 34, 32, 16, 22, 27, 22, 39, 30, 29, 50, 31, 15, 32, 29, 29, 28, 40, 18, 28, 28, 44, 36, 22, 35, 42, 31, 20, 20, 36, 23, 35, 30, 21, 22, 31, 55, 29, 27, 48, 40, 33, 37, 35, 31, 31, 34, 37, 24, 30, 27, 37, 28, 43, 38, 32, 30, 30, 27, 27, 31, 37, 14, 26, 29, 27, 27, 34, 28, 32, 19, 18, 39, 36, 27, 36, 29, 18, 27, 33, 31, 23, 21, 33, 30, 29, 22, 27, 27, 22, 38, 22, 17, 31, 22, 29, 22, 20, 27, 20, 24, 33, 30, 28, 11, 31, 23, 35, 52, 11, 26, 23, 28, 31, 37, 24, 18, 7, 14, 33, 15, 21, 32, 14, 28, 31, 35, 20, 29, 17, 55, 27, 27, 39, 20, 29, 22, 25, 34, 30, 47, 30, 22, 24, 27, 12, 35, 22, 29, 47, 32, 27, 25, 16, 32, 13, 42, 26, 21, 17, 32, 18, 37, 26, 34, 32, 30, 24, 33, 17, 29, 42, 24, 29, 30, 41, 20, 8, 17, 23, 32, 29, 27, 25, 27, 30, 21, 16, 26, 27, 17, 27, 24, 15, 24, 17, 39, 27, 26, 19, 10, 31, 39, 67, 23, 19, 18, 31, 33, 28, 10, 24, 28, 31, 35, 26, 32, 29, 21, 18, 22, 35, 47, 30, 28, 23, 23, 40, 31, 9, 12, 40, 34, 14, 17, 22, 38, 39, 22, 21, 23, 23, 33, 32, 29, 22, 19, 37, 35, 38, 22, 25, 20, 32, 35, 31, 25, 20, 31, 38, 26, 27, 41, 35, 37, 36, 34, 28, 32, 34, 40, 16, 20, 14, 47, 42, 33, 10, 22, 28, 32, 23, 21, 19, 29, 13, 39, 15, 41, 39, 33, 46, 35, 30, 31, 27, 36, 22, 36, 30, 39, 30, 28, 40, 22, 16, 25, 22, 20, 35, 43, 39, 15, 25, 29, 29, 22, 25, 28, 27, 8, 16, 31, 36, 29, 32, 21, 31, 38, 39, 35, 16, 38, 28, 36, 46, 33, 24, 25, 31, 22, 15, 34, 29, 34, 22, 36, 28, 33, 22, 53, 28, 24, 28, 23, 12, 24, 49, 25, 36, 34, 48, 23, 31, 24, 44, 33, 29, 52, 30, 25, 23, 34, 33, 40, 36, 27, 24, 52, 26, 18, 25, 18, 26, 11, 18, 29, 7, 30, 25, 34, 33, 25, 39, 27, 26, 30, 67, 31, 17, 19, 25, 27, 29, 20, 25, 36, 41, 33, 35, 28, 29, 56, 39, 29, 18, 31, 17, 29, 53, 28, 24, 29, 47, 27, 29, 28, 53, 30, 20, 25, 28, 35, 25, 27, 29, 25, 21, 29, 13, 16, 31, 29, 33, 22, 32, 26, 27, 26, 34, 22, 35, 45, 12, 29, 37, 47, 50, 37, 10, 24, 30, 36, 40, 43, 39, 27, 31, 25, 41, 29, 44, 23, 42, 32, 25, 30, 36, 46, 24, 45, 24, 23, 42, 23, 27, 23, 18, 43, 11, 35, 31, 26, 30, 35, 22, 20, 34, 50, 43, 40, 31, 35, 56, 30, 52, 20, 24, 7, 21, 41, 28, 29, 29, 27, 23, 20, 28, 25, 44, 20, 37, 23, 31, 32, 33, 23, 22, 32, 14, 30, 32, 34, 38, 11, 39, 18, 49, 20, 34, 44, 42, 29, 25, 29, 26, 15, 17, 16, 22, 26, 26, 39, 28, 10, 34, 18, 33, 28, 24, 34, 28, 22, 33, 17, 33, 31, 19, 28, 26, 30, 29, 27, 23, 37, 20, 31, 46, 42, 23, 34, 34, 55, 25, 25, 61, 18, 24, 24, 33, 23, 28, 28, 24, 25, 31, 17, 25, 30, 37, 53, 32, 40, 33, 40, 23, 23, 20, 32, 52, 30, 35, 33, 38, 27, 33, 35, 41, 37, 27, 30, 33, 24, 19, 27, 23, 41, 27, 48, 21, 19, 21, 15, 30, 17, 27, 27, 34, 33, 11, 13, 33, 28, 25, 27, 12, 33, 24, 47, 29, 36, 26, 21, 31, 23, 25, 24, 27, 29, 30, 32, 22, 29, 25, 15, 26, 25, 26, 24, 33, 34, 25, 17, 21, 27, 19, 38, 24, 26, 39, 9, 32, 29, 27, 35, 18, 21, 40, 56, 38, 33, 47, 32, 12, 40, 20, 22, 22, 15, 9, 43, 27, 23, 33, 30, 26, 24, 14, 32, 20, 45, 28, 30, 24, 40, 37, 10, 42, 17, 28, 20, 22, 23, 53, 28, 38]\n"
     ]
    }
   ],
   "source": [
    "for x in range(200):\n",
    "    Genetic1.Reproduction()\n",
    "    Genetic1.Evaluate()\n",
    "print(Genetic1.Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477 67\n",
      "ss\n",
      "[[  0.   0.  16.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "1\n",
      "[[  0.   2.  16.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "2\n",
      "[[  0.   4.  16.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "3\n",
      "[[  0.   4.  16.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "4\n",
      "[[  0.   4.  16.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "5\n",
      "[[  0.   4.  16.]\n",
      " [  0.   8.  32.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "6\n",
      "[[  0.   4.  16.]\n",
      " [  0.  16.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "7\n",
      "[[  0.   4.  16.]\n",
      " [  0.  16.  32.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "8\n",
      "[[  0.   4.  16.]\n",
      " [  0.  16.  32.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "9\n",
      "[[  0.   4.  16.]\n",
      " [  0.  16.  32.]\n",
      " [  0.   4.  16.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "10\n",
      "[[  0.   4.  16.]\n",
      " [  0.  16.  32.]\n",
      " [  0.   4.  16.]\n",
      " [  0.   8.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "11\n",
      "[[  0.   4.  16.]\n",
      " [  0.  16.  32.]\n",
      " [  0.   4.  16.]\n",
      " [  0.   8.  64.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "12\n",
      "[[  2.   4.  16.]\n",
      " [  0.  16.  32.]\n",
      " [  0.   4.  16.]\n",
      " [  0.   8.  64.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "13\n",
      "[[  2.   4.  16.]\n",
      " [  8.  16.  32.]\n",
      " [  0.   4.  16.]\n",
      " [  0.   8.  64.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "14\n",
      "[[  2.   4.  16.]\n",
      " [  8.  16.  32.]\n",
      " [  0.   4.  16.]\n",
      " [  0.   8.  64.]\n",
      " [  0.   0.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "15\n",
      "[[  2.   4.  16.]\n",
      " [  8.  16.  32.]\n",
      " [  2.   4.  16.]\n",
      " [  0.   8.  64.]\n",
      " [  0.   0.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "16\n",
      "[[  2.   4.  16.]\n",
      " [ 32.   8.  32.]\n",
      " [  0.   0.  16.]\n",
      " [  0.   0.  64.]\n",
      " [  0.   0.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "17\n",
      "[[  2.   4.  16.]\n",
      " [  0.  96.  64.]\n",
      " [  0.   0.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "18\n",
      "[[  2.   4.  16.]\n",
      " [  0.  96.  64.]\n",
      " [  0.   0.  32.]\n",
      " [  0.   0.   4.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "19\n",
      "[[  2.   4.  16.]\n",
      " [  0.  96.  64.]\n",
      " [  0.   0.  32.]\n",
      " [  0.   0.   4.]\n",
      " [  0.   0.   2.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "20\n",
      "[[  2.   4.  16.]\n",
      " [  0.  96.  64.]\n",
      " [  0.   0.  32.]\n",
      " [  0.   0.   4.]\n",
      " [  0.   0.   2.]\n",
      " [  0.   0.  16.]\n",
      " [  0.   0.   0.]]\n",
      "21\n",
      "[[  2.   4.  16.]\n",
      " [  0.  96.  64.]\n",
      " [  0.   8.  32.]\n",
      " [  0.   0.   4.]\n",
      " [  0.   0.   2.]\n",
      " [  0.   0.  16.]\n",
      " [  0.   0.   0.]]\n",
      "22\n",
      "[[  2.   4.  16.]\n",
      " [  0.  96.  64.]\n",
      " [  0.   8.  32.]\n",
      " [  0.   0.   4.]\n",
      " [  0.   0.   2.]\n",
      " [  0.   0.  16.]\n",
      " [  0.   0.  32.]]\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "def buscarmax(lista):\n",
    "    i=0\n",
    "    maxx=0\n",
    "    for x in range(len(lista)):\n",
    "        if (lista[x]>maxx):\n",
    "            maxx=lista[x]\n",
    "            i=x\n",
    "    print(i,maxx)\n",
    "    return i\n",
    "mejor= buscarmax(Genetic1.Evaluation)\n",
    "\n",
    "verjugar(Genetic1.Population[mejor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 96.0, 64.0, 128.0, 64.0, 128.0, 64.0, 128.0, 256.0, 256.0, 128.0, 128.0, 64.0, 32.0, 256.0, 128.0, 128.0, 128.0, 64.0, 32.0, 256.0, 64.0, 128.0, 64.0, 128.0, 64.0, 128.0, 128.0, 256.0, 128.0, 64.0, 128.0, 64.0, 128.0, 64.0, 128.0, 256.0, 64.0, 64.0, 128.0, 96.0, 64.0, 128.0, 64.0, 128.0, 64.0, 64.0, 64.0, 128.0, 32.0, 256.0, 64.0, 256.0, 128.0, 96.0, 64.0, 128.0, 32.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 192.0, 128.0, 256.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 64.0, 64.0, 128.0, 128.0, 256.0, 32.0, 128.0, 64.0, 64.0, 128.0, 128.0, 32.0, 64.0, 96.0, 256.0, 64.0, 192.0, 128.0, 128.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 64.0, 128.0, 96.0, 128.0, 96.0, 128.0, 64.0, 192.0, 128.0, 256.0, 128.0, 128.0, 256.0, 64.0, 96.0, 128.0, 128.0, 64.0, 256.0, 128.0, 128.0, 128.0, 96.0, 128.0, 256.0, 256.0, 256.0, 64.0, 64.0, 128.0, 64.0, 256.0, 64.0, 128.0, 96.0, 64.0, 128.0, 256.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 32.0, 64.0, 96.0, 128.0, 128.0, 256.0, 64.0, 128.0, 128.0, 64.0, 64.0, 64.0, 64.0, 128.0, 64.0, 128.0, 256.0, 64.0, 64.0, 256.0, 192.0, 192.0, 128.0, 64.0, 64.0, 128.0, 32.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 96.0, 128.0, 128.0, 96.0, 256.0, 64.0, 64.0, 128.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 256.0, 64.0, 128.0, 256.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 64.0, 64.0, 128.0, 64.0, 128.0, 256.0, 256.0, 128.0, 128.0, 128.0, 128.0, 96.0, 128.0, 64.0, 128.0, 128.0, 128.0, 256.0, 64.0, 128.0, 128.0, 256.0, 128.0, 64.0, 64.0, 64.0, 128.0, 256.0, 128.0, 64.0, 64.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 96.0, 96.0, 64.0, 192.0, 48.0, 128.0, 256.0, 96.0, 64.0, 64.0, 128.0, 128.0, 128.0, 256.0, 96.0, 64.0, 64.0, 64.0, 256.0, 64.0, 256.0, 256.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 96.0, 128.0, 128.0, 96.0, 128.0, 128.0, 128.0, 256.0, 128.0, 48.0, 64.0, 128.0, 128.0, 64.0, 256.0, 128.0, 64.0, 256.0, 256.0, 64.0, 128.0, 64.0, 128.0, 256.0, 128.0, 64.0, 128.0, 256.0, 128.0, 192.0, 32.0, 256.0, 128.0, 64.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 32.0, 32.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 256.0, 128.0, 64.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 64.0, 128.0, 96.0, 64.0, 128.0, 128.0, 64.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 64.0, 32.0, 128.0, 64.0, 256.0, 256.0, 96.0, 128.0, 64.0, 128.0, 256.0, 64.0, 128.0, 64.0, 32.0, 256.0, 64.0, 256.0, 256.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 64.0, 64.0, 64.0, 128.0, 128.0, 96.0, 192.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 64.0, 64.0, 32.0, 128.0, 128.0, 128.0, 64.0, 64.0, 64.0, 256.0, 128.0, 128.0, 64.0, 128.0, 64.0, 128.0, 128.0, 64.0, 192.0, 64.0, 64.0, 64.0, 64.0, 128.0, 256.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 192.0, 64.0, 64.0, 128.0, 128.0, 128.0, 64.0, 64.0, 128.0, 64.0, 64.0, 128.0, 96.0, 128.0, 64.0, 192.0, 128.0, 128.0, 128.0, 128.0, 32.0, 64.0, 64.0, 192.0, 64.0, 128.0, 32.0, 64.0, 256.0, 128.0, 128.0, 128.0, 128.0, 32.0, 128.0, 128.0, 128.0, 32.0, 128.0, 128.0, 256.0, 32.0, 64.0, 128.0, 256.0, 256.0, 128.0, 64.0, 128.0, 64.0, 128.0, 64.0, 128.0, 64.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 96.0, 64.0, 128.0, 64.0, 96.0, 128.0, 96.0, 64.0, 64.0, 128.0, 128.0, 256.0, 64.0, 128.0, 64.0, 128.0, 128.0, 32.0, 128.0, 32.0, 64.0, 128.0, 32.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 256.0, 96.0, 256.0, 128.0, 64.0, 256.0, 128.0, 256.0, 256.0, 128.0, 96.0, 96.0, 192.0, 128.0, 96.0, 64.0, 64.0, 64.0, 96.0, 128.0, 96.0, 128.0, 128.0, 256.0, 64.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 256.0, 64.0, 128.0, 64.0, 128.0, 64.0, 128.0, 256.0, 64.0, 192.0, 64.0, 64.0, 128.0, 256.0, 96.0, 64.0, 256.0, 128.0, 128.0, 256.0, 96.0, 32.0, 128.0, 128.0, 128.0, 64.0, 64.0, 512.0, 128.0, 128.0, 32.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 256.0, 128.0, 64.0, 256.0, 64.0, 128.0, 128.0, 96.0, 128.0, 64.0, 96.0, 64.0, 128.0, 128.0, 128.0, 128.0, 32.0, 128.0, 64.0, 96.0, 64.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 64.0, 64.0, 64.0, 64.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 256.0, 64.0, 128.0, 256.0, 256.0, 64.0, 32.0, 128.0, 96.0, 32.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 128.0, 256.0, 256.0, 128.0, 64.0, 128.0, 128.0, 128.0, 256.0, 128.0, 64.0, 64.0, 128.0, 128.0, 64.0, 128.0, 64.0, 64.0, 64.0, 256.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 256.0, 128.0, 64.0, 64.0, 64.0, 256.0, 256.0, 256.0, 128.0, 96.0, 128.0, 32.0, 64.0, 128.0, 128.0, 256.0, 96.0, 64.0, 128.0, 256.0, 96.0, 256.0, 256.0, 128.0, 32.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 96.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 64.0, 128.0, 64.0, 64.0, 128.0, 32.0, 128.0, 256.0, 64.0, 192.0, 128.0, 128.0, 64.0, 64.0, 128.0, 128.0, 64.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 32.0, 64.0, 128.0, 512.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 256.0, 32.0, 64.0, 128.0, 128.0, 128.0, 128.0, 256.0, 96.0, 32.0, 64.0, 64.0, 96.0, 64.0, 32.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 96.0, 64.0, 256.0, 256.0, 128.0, 64.0, 32.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 96.0, 64.0, 64.0, 64.0, 128.0, 128.0, 32.0, 128.0, 128.0, 256.0, 128.0, 64.0, 64.0, 256.0, 128.0, 64.0, 128.0, 128.0, 64.0, 64.0, 128.0, 64.0, 128.0, 256.0, 128.0, 128.0, 96.0, 256.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 64.0, 128.0, 64.0, 128.0, 128.0, 256.0, 128.0, 64.0, 64.0, 64.0, 128.0, 128.0, 64.0, 192.0, 64.0, 64.0, 128.0, 96.0, 128.0, 128.0, 32.0, 256.0, 128.0, 64.0, 96.0, 256.0, 64.0, 256.0, 64.0, 128.0, 128.0, 128.0, 64.0, 256.0, 128.0, 128.0, 64.0, 256.0, 256.0, 96.0, 128.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 64.0, 64.0, 64.0, 128.0, 64.0, 32.0, 128.0, 64.0, 128.0, 64.0, 128.0, 96.0, 128.0, 128.0, 128.0, 96.0, 96.0, 64.0, 128.0, 128.0, 192.0, 256.0, 96.0, 128.0, 128.0, 128.0, 256.0, 128.0, 96.0, 32.0, 128.0, 64.0, 128.0, 64.0, 256.0, 64.0, 256.0, 64.0, 64.0, 128.0, 96.0, 64.0, 64.0, 48.0, 64.0, 64.0, 256.0, 64.0, 64.0, 128.0, 96.0, 128.0, 64.0, 128.0, 128.0, 96.0, 96.0, 64.0, 64.0, 64.0, 128.0, 96.0, 64.0, 32.0, 128.0, 192.0, 128.0, 128.0, 128.0, 128.0, 256.0, 64.0, 64.0, 128.0, 128.0, 64.0, 64.0, 128.0, 128.0, 64.0, 128.0, 64.0, 256.0, 128.0, 256.0, 96.0, 128.0, 64.0, 128.0, 128.0, 128.0]\n"
     ]
    }
   ],
   "source": [
    "def Evaluador1(indv):\n",
    "    game= Game(3,7)\n",
    "    acapa1=[]\n",
    "    acapa2=[]\n",
    "    for x in range(28):\n",
    "        if(x<25):\n",
    "            acapa1.append(indv[x])\n",
    "        else:\n",
    "            acapa2.append(indv[x])\n",
    "    Capa1= Capa()\n",
    "    Capa2=Capa()\n",
    "    Capa1.setperceptrones(acapa1)\n",
    "    Capa2.setperceptrones(acapa2)\n",
    "    red1= Red_Neuronal()\n",
    "    red1.setcapinicial(Capa1) #Capa incial.\n",
    "    red1.setcapfinal(Capa2) #Capa final\n",
    "    red1.enlazar()\n",
    "    mov=0\n",
    "    while(game.end==0):\n",
    "        valor= choice([2.0,4.0,8.0,16.0,32.0])\n",
    "        entrada=[]\n",
    "        entrada.append(valor)\n",
    "        for fila in game.mesa:\n",
    "            for celda in fila:\n",
    "                entrada.append(celda)\n",
    "        red1.capinicial.getinput(normalizar(entrada))\n",
    "        red1.capinicial.Feeding()\n",
    "        \n",
    "        outp=red1.capfinal.output\n",
    "        i=0\n",
    "        maxx=0\n",
    "        i2=0\n",
    "        for xot in outp:\n",
    "            if(maxx<=xot):\n",
    "                i2=i\n",
    "                maxx=xot\n",
    "            i=i+1\n",
    "        x= game.movimiento(i2,valor)\n",
    "        game.verifica_multiplos(x,i2)\n",
    "        #print(game.mesa)\n",
    "        mov=mov+1\n",
    "    puntaje= MaxValoMesa(game.mesa)\n",
    "    return puntaje\n",
    "\n",
    "Genetic1.Fitness=Evaluador1\n",
    "Genetic1.Evaluate()\n",
    "print(Genetic1.Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256.0, 64.0, 64.0, 256.0, 128.0, 128.0, 128.0, 64.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 32.0, 128.0, 128.0, 256.0, 128.0, 192.0, 128.0, 128.0, 128.0, 256.0, 64.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 64.0, 64.0, 64.0, 128.0, 128.0, 64.0, 64.0, 64.0, 64.0, 256.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 256.0, 96.0, 96.0, 128.0, 128.0, 64.0, 256.0, 96.0, 64.0, 128.0, 256.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 96.0, 64.0, 128.0, 96.0, 256.0, 64.0, 128.0, 128.0, 64.0, 256.0, 128.0, 128.0, 256.0, 64.0, 256.0, 128.0, 128.0, 256.0, 128.0, 64.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 256.0, 128.0, 64.0, 128.0, 64.0, 256.0, 128.0, 128.0, 64.0, 128.0, 64.0, 64.0, 128.0, 64.0, 128.0, 128.0, 256.0, 64.0, 128.0, 128.0, 128.0, 256.0, 256.0, 256.0, 256.0, 64.0, 128.0, 128.0, 64.0, 64.0, 128.0, 256.0, 128.0, 96.0, 256.0, 128.0, 64.0, 256.0, 64.0, 64.0, 32.0, 256.0, 256.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 32.0, 256.0, 128.0, 128.0, 64.0, 128.0, 96.0, 64.0, 128.0, 128.0, 256.0, 128.0, 64.0, 256.0, 128.0, 96.0, 128.0, 256.0, 128.0, 32.0, 256.0, 128.0, 128.0, 128.0, 96.0, 256.0, 256.0, 256.0, 512.0, 256.0, 256.0, 64.0, 64.0, 128.0, 32.0, 64.0, 128.0, 128.0, 64.0, 256.0, 128.0, 32.0, 256.0, 128.0, 384.0, 128.0, 128.0, 64.0, 128.0, 128.0, 96.0, 128.0, 128.0, 64.0, 96.0, 256.0, 128.0, 96.0, 256.0, 128.0, 128.0, 64.0, 64.0, 256.0, 128.0, 256.0, 128.0, 128.0, 256.0, 64.0, 192.0, 128.0, 256.0, 256.0, 64.0, 256.0, 128.0, 128.0, 256.0, 256.0, 128.0, 256.0, 64.0, 256.0, 64.0, 128.0, 128.0, 256.0, 64.0, 128.0, 64.0, 64.0, 64.0, 64.0, 128.0, 16.0, 64.0, 64.0, 16.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 256.0, 64.0, 64.0, 256.0, 256.0, 128.0, 128.0, 64.0, 128.0, 256.0, 64.0, 256.0, 32.0, 128.0, 128.0, 64.0, 64.0, 128.0, 256.0, 64.0, 64.0, 128.0, 128.0, 256.0, 128.0, 128.0, 256.0, 256.0, 128.0, 128.0, 128.0, 192.0, 128.0, 128.0, 128.0, 64.0, 256.0, 256.0, 96.0, 128.0, 256.0, 128.0, 64.0, 128.0, 128.0, 128.0, 256.0, 128.0, 64.0, 128.0, 256.0, 64.0, 32.0, 64.0, 256.0, 64.0, 64.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 256.0, 128.0, 64.0, 128.0, 128.0, 256.0, 128.0, 128.0, 64.0, 64.0, 128.0, 128.0, 64.0, 64.0, 16.0, 128.0, 64.0, 64.0, 192.0, 256.0, 128.0, 64.0, 96.0, 256.0, 64.0, 64.0, 128.0, 256.0, 96.0, 128.0, 256.0, 128.0, 256.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 64.0, 64.0, 32.0, 128.0, 128.0, 128.0, 256.0, 128.0, 32.0, 128.0, 128.0, 128.0, 192.0, 256.0, 96.0, 64.0, 96.0, 64.0, 128.0, 128.0, 64.0, 64.0, 64.0, 64.0, 64.0, 128.0, 128.0, 256.0, 64.0, 128.0, 192.0, 64.0, 128.0, 256.0, 64.0, 128.0, 128.0, 256.0, 256.0, 96.0, 64.0, 64.0, 128.0, 128.0, 256.0, 64.0, 192.0, 64.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 256.0, 96.0, 128.0, 64.0, 256.0, 128.0, 128.0, 256.0, 64.0, 128.0, 128.0, 64.0, 128.0, 64.0, 96.0, 128.0, 48.0, 128.0, 128.0, 128.0, 256.0, 128.0, 64.0, 128.0, 192.0, 64.0, 128.0, 128.0, 16.0, 128.0, 64.0, 64.0, 64.0, 64.0, 128.0, 256.0, 128.0, 64.0, 128.0, 128.0, 256.0, 128.0, 64.0, 64.0, 32.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 32.0, 128.0, 128.0, 64.0, 128.0, 128.0, 96.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 64.0, 32.0, 64.0, 128.0, 64.0, 64.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 96.0, 64.0, 128.0, 256.0, 32.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 256.0, 128.0, 256.0, 128.0, 128.0, 192.0, 64.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 96.0, 64.0, 96.0, 64.0, 128.0, 256.0, 128.0, 256.0, 32.0, 128.0, 128.0, 256.0, 128.0, 192.0, 64.0, 128.0, 128.0, 128.0, 128.0, 64.0, 96.0, 128.0, 128.0, 64.0, 64.0, 256.0, 64.0, 256.0, 128.0, 128.0, 128.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 256.0, 64.0, 64.0, 64.0, 256.0, 64.0, 128.0, 128.0, 32.0, 32.0, 64.0, 128.0, 96.0, 64.0, 64.0, 256.0, 128.0, 96.0, 128.0, 256.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 64.0, 128.0, 64.0, 256.0, 256.0, 64.0, 128.0, 256.0, 128.0, 128.0, 128.0, 64.0, 256.0, 128.0, 128.0, 64.0, 32.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 256.0, 128.0, 128.0, 64.0, 128.0, 192.0, 128.0, 128.0, 256.0, 256.0, 64.0, 128.0, 96.0, 128.0, 128.0, 64.0, 64.0, 128.0, 64.0, 256.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 256.0, 256.0, 128.0, 128.0, 96.0, 256.0, 128.0, 128.0, 64.0, 32.0, 128.0, 64.0, 64.0, 128.0, 64.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 512.0, 256.0, 128.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 256.0, 64.0, 128.0, 128.0, 32.0, 256.0, 64.0, 128.0, 96.0, 256.0, 128.0, 32.0, 128.0, 128.0, 256.0, 64.0, 128.0, 128.0, 128.0, 256.0, 128.0, 256.0, 64.0, 128.0, 128.0, 64.0, 128.0, 96.0, 256.0, 128.0, 128.0, 128.0, 192.0, 32.0, 64.0, 128.0, 128.0, 128.0, 256.0, 256.0, 256.0, 128.0, 128.0, 128.0, 64.0, 128.0, 128.0, 128.0, 256.0, 256.0, 128.0, 96.0, 64.0, 128.0, 128.0, 64.0, 96.0, 256.0, 128.0, 128.0, 128.0, 64.0, 256.0, 32.0, 128.0, 256.0, 128.0, 256.0, 192.0, 64.0, 128.0, 128.0, 96.0, 64.0, 128.0, 64.0, 128.0, 64.0, 256.0, 128.0, 64.0, 128.0, 128.0, 256.0, 128.0, 64.0, 128.0, 96.0, 96.0, 128.0, 256.0, 256.0, 128.0, 64.0, 64.0, 128.0, 128.0, 128.0, 128.0, 64.0, 64.0, 128.0, 64.0, 64.0, 64.0, 16.0, 96.0, 96.0, 64.0, 64.0, 256.0, 64.0, 128.0, 192.0, 128.0, 128.0, 128.0, 96.0, 256.0, 128.0, 64.0, 128.0, 64.0, 128.0, 64.0, 64.0, 128.0, 64.0, 256.0, 192.0, 64.0, 192.0, 64.0, 64.0, 128.0, 64.0, 128.0, 192.0, 64.0, 128.0, 128.0, 64.0, 96.0, 48.0, 128.0, 128.0, 128.0, 32.0, 128.0, 128.0, 64.0, 64.0, 256.0, 256.0, 64.0, 64.0, 256.0, 128.0, 256.0, 128.0, 192.0, 128.0, 128.0, 64.0, 64.0, 256.0, 64.0, 256.0, 256.0, 256.0, 128.0, 192.0, 256.0, 128.0, 128.0, 128.0, 128.0, 128.0, 256.0, 32.0, 32.0, 64.0, 128.0, 48.0, 64.0, 64.0, 96.0, 96.0, 128.0, 128.0, 64.0, 128.0, 256.0, 64.0, 128.0, 96.0, 128.0, 128.0, 64.0, 64.0, 256.0, 64.0, 128.0, 64.0, 128.0, 128.0, 128.0, 128.0, 128.0, 64.0, 128.0, 64.0, 96.0, 32.0, 256.0, 64.0, 128.0, 128.0, 128.0, 192.0, 64.0, 128.0, 128.0, 128.0, 256.0, 128.0, 128.0, 128.0, 64.0, 256.0, 64.0, 64.0, 256.0, 256.0, 128.0, 64.0, 128.0, 128.0, 64.0, 32.0, 64.0, 128.0, 64.0, 128.0, 128.0, 256.0, 64.0, 256.0, 32.0, 192.0, 128.0, 64.0, 64.0, 32.0, 128.0, 128.0, 256.0, 256.0]\n"
     ]
    }
   ],
   "source": [
    "for x in range(200):\n",
    "    Genetic1.Reproduction()\n",
    "    Genetic1.Evaluate()\n",
    "print(Genetic1.Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 512.0\n",
      "ss\n",
      "[[ 0.  2.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "1\n",
      "[[  0.   2.  16.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "2\n",
      "[[  0.   2.  16.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "3\n",
      "[[  0.   2.  16.]\n",
      " [  0.  16.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "4\n",
      "[[  0.   2.  16.]\n",
      " [  0.  16.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "5\n",
      "[[  0.   2.  16.]\n",
      " [  0.  16.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "6\n",
      "[[  0.   2.  16.]\n",
      " [  0.  16.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "7\n",
      "[[  0.   2.  16.]\n",
      " [  0.  16.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]]\n",
      "8\n",
      "[[  0.   2.  16.]\n",
      " [  0.  16.   8.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]]\n",
      "9\n",
      "[[  0.   2.  16.]\n",
      " [  0.  16.   8.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]]\n",
      "10\n",
      "[[  4.  32.   8.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "11\n",
      "[[  4.  32.   8.]\n",
      " [  0.   2.  16.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "12\n",
      "[[  8.  32.   8.]\n",
      " [  0.   4.  16.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "13\n",
      "[[  8.  32.   8.]\n",
      " [  0.   4.  16.]\n",
      " [  0.   2.  32.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "14\n",
      "[[  8.  32.   8.]\n",
      " [  0.   4.  16.]\n",
      " [  0.   2.  32.]\n",
      " [  0.   0.  16.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "15\n",
      "[[  8.  32.   8.]\n",
      " [  0.   8.  16.]\n",
      " [  0.   0.  32.]\n",
      " [  0.   0.  16.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "16\n",
      "[[  8.  32.   8.]\n",
      " [  0.   8.  16.]\n",
      " [  0.   4.  32.]\n",
      " [  0.   0.  16.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "17\n",
      "[[  8.  64.   8.]\n",
      " [  0.   0.  32.]\n",
      " [  0.   0.  16.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "18\n",
      "[[  8.  64.   8.]\n",
      " [  0.   4.  32.]\n",
      " [  0.   0.  16.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "19\n",
      "[[  8.  64.   8.]\n",
      " [  0.   4.  32.]\n",
      " [  0.   8.  16.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "20\n",
      "[[  8.  64.   8.]\n",
      " [  0.   4.  32.]\n",
      " [  0.  32.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "21\n",
      "[[  8.  64.   8.]\n",
      " [  0.   4.  96.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "22\n",
      "[[  8.  64.   8.]\n",
      " [  0.   4.  96.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "23\n",
      "[[  8.  64.   8.]\n",
      " [  0.   4.  96.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "24\n",
      "[[  8.  64.   8.]\n",
      " [  0.   4.  96.]\n",
      " [  0.   2.  16.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "25\n",
      "[[  8.  64.   8.]\n",
      " [  0.   4.  96.]\n",
      " [  0.   2.  16.]\n",
      " [  0.   4.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "26\n",
      "[[  8.  64.   8.]\n",
      " [  2.   4.  96.]\n",
      " [  0.   2.  16.]\n",
      " [  0.   4.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "27\n",
      "[[  8.  64.   8.]\n",
      " [  2.   4.  96.]\n",
      " [  0.   2.  16.]\n",
      " [  0.   4.  64.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "28\n",
      "[[  8.  64.   8.]\n",
      " [  2.   4.  96.]\n",
      " [  0.   2.  16.]\n",
      " [  0.   4.  64.]\n",
      " [  0.   0.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "29\n",
      "[[  8.  64.   8.]\n",
      " [  2.   4.  96.]\n",
      " [ 16.   2.  16.]\n",
      " [  0.   4.  64.]\n",
      " [  0.   0.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "30\n",
      "[[  8.  64.   8.]\n",
      " [  2.   4.  96.]\n",
      " [ 16.   2.  16.]\n",
      " [  0.   4.  64.]\n",
      " [  0.  16.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "31\n",
      "[[  8.  64.   8.]\n",
      " [  2.   4.  96.]\n",
      " [ 16.   2.  16.]\n",
      " [  8.  16.  64.]\n",
      " [  0.   0.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "32\n",
      "[[  8.  64.   8.]\n",
      " [  2.   4.  96.]\n",
      " [ 16.   2.  16.]\n",
      " [  8.  16.  64.]\n",
      " [  2.   0.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "33\n",
      "[[   8.   64.    8.]\n",
      " [   2.    4.   96.]\n",
      " [  16.    2.   16.]\n",
      " [   8.   16.  128.]\n",
      " [   2.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "34\n",
      "[[   8.   64.    8.]\n",
      " [   2.    4.   96.]\n",
      " [  16.    2.   16.]\n",
      " [   8.   16.  128.]\n",
      " [   2.    0.   32.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "35\n",
      "[[   8.   64.    8.]\n",
      " [   2.    4.   96.]\n",
      " [  16.    2.   16.]\n",
      " [   8.   16.  128.]\n",
      " [   2.    0.   32.]\n",
      " [  32.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "36\n",
      "[[   8.   64.    8.]\n",
      " [   2.    4.   96.]\n",
      " [  16.    2.   16.]\n",
      " [   8.   16.  128.]\n",
      " [   2.    4.   32.]\n",
      " [  32.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "37\n",
      "[[   8.   64.    8.]\n",
      " [   2.    4.   96.]\n",
      " [  16.    2.   16.]\n",
      " [   8.   16.  128.]\n",
      " [   2.    4.   32.]\n",
      " [  32.    0.    0.]\n",
      " [   2.    0.    0.]]\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "def buscarmax(lista):\n",
    "    i=0\n",
    "    maxx=0\n",
    "    for x in range(len(lista)):\n",
    "        if (lista[x]>maxx):\n",
    "            maxx=lista[x]\n",
    "            i=x\n",
    "    print(i,maxx)\n",
    "    return i\n",
    "mejor= buscarmax(Genetic1.Evaluation)\n",
    "\n",
    "verjugar(Genetic1.Population[mejor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4608.0, 2688.0, 9984.0, 3200.0, 3840.0, 9472.0, 1664.0, 4352.0, 1408.0, 3328.0, 2560.0, 2816.0, 4608.0, 1728.0, 3968.0, 3840.0, 3072.0, 3840.0, 4352.0, 3840.0, 2784.0, 1088.0, 1408.0, 544.0, 3712.0, 3328.0, 1792.0, 9984.0, 10752.0, 3200.0, 2016.0, 4352.0, 4128.0, 6912.0, 3200.0, 1728.0, 4096.0, 1728.0, 7872.0, 5120.0, 4096.0, 4352.0, 2816.0, 5632.0, 1152.0, 5120.0, 12288.0, 1216.0, 10496.0, 3072.0, 8064.0, 896.0, 8448.0, 3200.0, 2560.0, 384.0, 3072.0, 3584.0, 1920.0, 1984.0, 896.0, 2944.0, 8448.0, 2208.0, 6400.0, 6656.0, 3072.0, 2112.0, 1600.0, 3968.0, 2688.0, 2944.0, 1856.0, 1392.0, 1664.0, 1600.0, 17408.0, 7936.0, 9728.0, 3968.0, 2304.0, 5120.0, 1152.0, 3264.0, 1344.0, 3072.0, 4352.0, 1408.0, 2688.0, 704.0, 3584.0, 1408.0, 3072.0, 8448.0, 2688.0, 2944.0, 2496.0, 1536.0, 1408.0, 4352.0, 4992.0, 3968.0, 8704.0, 3968.0, 4352.0, 2816.0, 4224.0, 1472.0, 6144.0, 4608.0, 7680.0, 1088.0, 1728.0, 8960.0, 4608.0, 3200.0, 1856.0, 5376.0, 7488.0, 2816.0, 1088.0, 4224.0, 3200.0, 6400.0, 1280.0, 4352.0, 4224.0, 7424.0, 960.0, 10752.0, 4992.0, 2688.0, 6912.0, 7936.0, 15616.0, 1088.0, 9472.0, 9728.0, 3328.0, 4608.0, 2816.0, 1408.0, 3968.0, 608.0, 4864.0, 1600.0, 1856.0, 11776.0, 4480.0, 3840.0, 2560.0, 5952.0, 4224.0, 3584.0, 1536.0, 4608.0, 1408.0, 8192.0, 8704.0, 3584.0, 1408.0, 3840.0, 1792.0, 4736.0, 3072.0, 1984.0, 6144.0, 11264.0, 3328.0, 1728.0, 1536.0, 3456.0, 1856.0, 7680.0, 896.0, 2240.0, 4352.0, 4480.0, 1216.0, 11776.0, 3712.0, 1664.0, 2304.0, 7936.0, 256.0, 13312.0, 4608.0, 4224.0, 10176.0, 3456.0, 1536.0, 4736.0, 3968.0, 3840.0, 896.0, 4608.0, 2112.0, 11776.0, 1728.0, 9216.0, 3840.0, 13056.0, 3584.0, 1920.0, 2688.0, 2944.0, 1856.0, 3456.0, 14336.0, 6912.0, 3968.0, 3328.0, 2944.0, 9984.0, 416.0, 13312.0, 672.0, 4736.0, 640.0, 3200.0, 3072.0, 3200.0, 13056.0, 1024.0, 3328.0, 1792.0, 10240.0, 4736.0, 4608.0, 2880.0, 3840.0, 8960.0, 1920.0, 3200.0, 3072.0, 2688.0, 2176.0, 3552.0, 8704.0, 13824.0, 1792.0, 1664.0, 4992.0, 5888.0, 2560.0, 2016.0, 3552.0, 3712.0, 4224.0, 6272.0, 3968.0, 6528.0, 1408.0, 1408.0, 2816.0, 1536.0, 4480.0, 10752.0, 6144.0, 1856.0, 3712.0, 12288.0, 1280.0, 1472.0, 3200.0, 5504.0, 11520.0, 8960.0, 5888.0, 4096.0, 1344.0, 2432.0, 5376.0, 10752.0, 1088.0, 3456.0, 2816.0, 2432.0, 960.0, 256.0, 5632.0, 3200.0, 1600.0, 1280.0, 13312.0, 4864.0, 1824.0, 960.0, 4736.0, 3328.0, 3712.0, 4864.0, 1920.0, 6144.0, 1088.0, 3328.0, 3456.0, 2208.0, 3712.0, 3456.0, 1472.0, 14592.0, 1536.0, 3200.0, 1600.0, 8192.0, 7936.0, 2400.0, 224.0, 16896.0, 1600.0, 2176.0, 3584.0, 1024.0, 1344.0, 1216.0, 3712.0, 9472.0, 3968.0, 1664.0, 3200.0, 4224.0, 1280.0, 1920.0, 4480.0, 7936.0, 1024.0, 1920.0, 5632.0, 4608.0, 2816.0, 9216.0, 2432.0, 4352.0, 11520.0, 1920.0, 3840.0, 4352.0, 3584.0, 3200.0, 1216.0, 576.0, 3840.0, 9728.0, 3328.0, 3712.0, 2176.0, 4480.0, 4736.0, 1984.0, 3840.0, 896.0, 8448.0, 3456.0, 1216.0, 8448.0, 28672.0, 2048.0, 3584.0, 3584.0, 2304.0, 1600.0, 3328.0, 5120.0, 4992.0, 1536.0, 224.0, 4608.0, 8448.0, 3712.0, 3456.0, 7936.0, 1024.0, 576.0, 8448.0, 3584.0, 1408.0, 1536.0, 9216.0, 1536.0, 2592.0, 4992.0, 2816.0, 4864.0, 5120.0, 9216.0, 7168.0, 3328.0, 11264.0, 4224.0, 3456.0, 6144.0, 4608.0, 9728.0, 1984.0, 3584.0, 2944.0, 4736.0, 512.0, 6720.0, 4992.0, 12544.0, 5376.0, 5632.0, 3328.0, 3840.0, 4864.0, 1664.0, 960.0, 1216.0, 2240.0, 2784.0, 1152.0, 3840.0, 9216.0, 1984.0, 10752.0, 5888.0, 3456.0, 1152.0, 3456.0, 6144.0, 3968.0, 4608.0, 8448.0, 3968.0, 4864.0, 1152.0, 2880.0, 1728.0, 3712.0, 4096.0, 2048.0, 3968.0, 4224.0, 3328.0, 3072.0, 1536.0, 3840.0, 1200.0, 3200.0, 768.0, 2944.0, 3456.0, 1472.0, 2176.0, 4992.0, 3200.0, 1024.0, 11008.0, 4352.0, 3840.0, 11264.0, 832.0, 2560.0, 2688.0, 3456.0, 1248.0, 10240.0, 2496.0, 4608.0, 8192.0, 4992.0, 7936.0, 7168.0, 3712.0, 2560.0, 4352.0, 3968.0, 5248.0, 1280.0, 8704.0, 10496.0, 8192.0, 1664.0, 1600.0, 7936.0, 4320.0, 4736.0, 8064.0, 4736.0, 1664.0, 4608.0, 1408.0, 4096.0, 4480.0, 3584.0, 16896.0, 3712.0, 2240.0, 6400.0, 2944.0, 3200.0, 6656.0, 33280.0, 2432.0, 1024.0, 2560.0, 5888.0, 4096.0, 4224.0, 9472.0, 1280.0, 3712.0, 1632.0, 4736.0, 2176.0, 832.0, 416.0, 1792.0, 960.0, 1280.0, 1664.0, 1536.0, 4864.0, 2112.0, 3168.0, 1792.0, 2432.0, 4608.0, 8960.0, 2880.0, 1280.0, 1344.0, 2496.0, 4736.0, 3328.0, 9984.0, 1600.0, 2560.0, 1280.0, 2688.0, 8960.0, 4096.0, 2176.0, 10496.0, 4480.0, 1664.0, 896.0, 3456.0, 1024.0, 11264.0, 5760.0, 2208.0, 8960.0, 2944.0, 3584.0, 3712.0, 7936.0, 2688.0, 4352.0, 1920.0, 14080.0, 3328.0, 3712.0, 3456.0, 1088.0, 1088.0, 9984.0, 4992.0, 9472.0, 3840.0, 13312.0, 7168.0, 1280.0, 288.0, 9472.0, 768.0, 4480.0, 8960.0, 4480.0, 1472.0, 3584.0, 704.0, 4096.0, 3584.0, 6400.0, 4032.0, 8960.0, 4352.0, 896.0, 8448.0, 4736.0, 7936.0, 4992.0, 2560.0, 5376.0, 2176.0, 4608.0, 2432.0, 3328.0, 4608.0, 3840.0, 8960.0, 6656.0, 3936.0, 4224.0, 6016.0, 3840.0, 1792.0, 1408.0, 6144.0, 4608.0, 1408.0, 1792.0, 4736.0, 1664.0, 3328.0, 1536.0, 960.0, 1984.0, 7104.0, 4864.0, 1344.0, 3968.0, 1920.0, 3328.0, 2688.0, 1472.0, 1088.0, 56.0, 3328.0, 3456.0, 1024.0, 4096.0, 4096.0, 4352.0, 12032.0, 1088.0, 2688.0, 1408.0, 8960.0, 1216.0, 1344.0, 768.0, 1216.0, 3584.0, 1472.0, 3840.0, 6528.0, 448.0, 7424.0, 2304.0, 2432.0, 3840.0, 8192.0, 4096.0, 3328.0, 1984.0, 8192.0, 2176.0, 11520.0, 1792.0, 9472.0, 2784.0, 3968.0, 1792.0, 1280.0, 12800.0, 8192.0, 8192.0, 1920.0, 13056.0, 960.0, 3200.0, 3712.0, 1024.0, 2816.0, 4864.0, 3456.0, 3456.0, 1344.0, 10752.0, 8448.0, 8192.0, 5248.0, 6912.0, 2944.0, 1344.0, 9472.0, 3584.0, 3712.0, 3200.0, 2816.0, 7424.0, 8192.0, 176.0, 1344.0, 4480.0, 5632.0, 4096.0, 9792.0, 3456.0, 3072.0, 2688.0, 1536.0, 4352.0, 6912.0, 3968.0, 1856.0, 4480.0, 4096.0, 7680.0, 3456.0, 11008.0, 3968.0, 4608.0, 3584.0, 6656.0, 1600.0, 9472.0, 4224.0, 12032.0, 12544.0, 8192.0, 7936.0, 4480.0, 960.0, 10496.0, 3968.0, 7168.0, 6528.0, 3968.0, 2816.0, 4096.0, 4480.0, 5632.0, 5248.0, 7424.0, 3328.0, 3072.0, 11520.0, 9728.0, 1344.0, 3968.0, 9472.0, 4096.0, 1856.0, 9024.0, 3456.0, 832.0, 7680.0, 2944.0, 224.0, 6272.0, 9216.0, 416.0, 6912.0, 3072.0, 2688.0, 8960.0, 1984.0, 4992.0, 1280.0, 3712.0, 6656.0, 7680.0, 3200.0, 1344.0, 2944.0, 1152.0, 8192.0, 4480.0, 1792.0, 2816.0, 960.0, 4480.0, 26624.0, 2496.0, 4480.0, 5888.0, 960.0, 12544.0, 448.0, 3712.0, 11776.0, 1152.0, 3712.0, 8704.0, 4992.0, 7424.0, 3072.0, 6912.0, 3072.0, 13312.0, 1600.0, 3200.0, 8960.0, 4096.0, 2112.0, 1920.0, 3968.0, 4224.0, 2304.0, 3712.0, 4096.0, 7168.0, 12544.0, 1408.0, 3456.0, 4352.0, 6656.0, 4224.0, 3200.0, 3840.0, 2944.0, 4224.0, 10752.0, 13568.0, 9216.0, 8960.0, 1920.0, 4352.0, 4736.0, 3968.0, 1728.0, 608.0, 2688.0, 3456.0, 4480.0, 10752.0, 1280.0, 2560.0, 9728.0, 4096.0, 3712.0, 3328.0, 1472.0, 3072.0, 4224.0, 3840.0, 3200.0, 5504.0, 4480.0, 3456.0, 9216.0, 3840.0, 2816.0, 9792.0, 1344.0, 2688.0, 1152.0, 8448.0, 3584.0, 6912.0, 2112.0, 3584.0, 4352.0, 6016.0, 1600.0, 9216.0, 3072.0, 2112.0, 2304.0, 3456.0, 3584.0, 4480.0, 4352.0, 3072.0, 3328.0, 4608.0, 1536.0, 1920.0, 960.0, 9216.0, 13056.0, 2944.0, 9216.0, 3328.0, 1088.0, 11264.0, 9216.0, 10752.0, 4608.0, 3840.0, 4224.0, 4736.0, 2112.0, 3328.0, 1856.0, 3968.0, 896.0, 3072.0, 3712.0, 3712.0, 1408.0, 4736.0, 640.0, 4096.0, 3200.0, 1344.0, 3712.0, 5120.0, 1664.0, 768.0, 3200.0, 1408.0, 2560.0, 7872.0, 4864.0, 6016.0, 5120.0, 5120.0, 11520.0, 6656.0, 3840.0, 4352.0, 608.0, 1920.0, 4992.0, 3584.0, 3456.0, 2432.0, 8064.0, 1216.0, 3168.0, 7680.0, 768.0, 2560.0, 5376.0, 10240.0, 3840.0, 2944.0, 640.0, 1472.0, 2176.0, 3072.0, 1600.0, 5632.0, 4352.0, 9216.0, 11520.0, 8192.0, 5760.0, 4608.0, 1600.0, 8960.0, 11520.0, 1280.0, 3584.0, 1280.0, 960.0, 2784.0, 4608.0, 3072.0, 7680.0, 2816.0, 704.0, 6912.0, 9984.0, 6400.0, 960.0, 4224.0, 3456.0, 9984.0, 1088.0, 4736.0, 4736.0, 9216.0, 1664.0, 2016.0, 2432.0, 736.0, 1344.0, 3712.0, 4736.0, 3200.0, 3072.0, 1472.0, 6912.0, 9216.0, 4608.0, 2240.0, 3584.0, 2816.0, 3200.0, 4224.0, 1536.0, 8704.0, 1792.0, 2784.0, 8256.0, 8192.0, 15104.0, 2880.0, 2944.0, 3456.0, 3584.0, 3200.0, 3968.0, 288.0, 3072.0, 1472.0, 416.0, 11008.0, 7680.0, 672.0, 5120.0, 1280.0, 9472.0]\n"
     ]
    }
   ],
   "source": [
    "def Evaluador2(indv):\n",
    "    game= Game(3,7)\n",
    "    acapa1=[]\n",
    "    acapa2=[]\n",
    "    for x in range(28):\n",
    "        if(x<25):\n",
    "            acapa1.append(indv[x])\n",
    "        else:\n",
    "            acapa2.append(indv[x])\n",
    "    Capa1= Capa()\n",
    "    Capa2=Capa()\n",
    "    Capa1.setperceptrones(acapa1)\n",
    "    Capa2.setperceptrones(acapa2)\n",
    "    red1= Red_Neuronal()\n",
    "    red1.setcapinicial(Capa1) #Capa incial.\n",
    "    red1.setcapfinal(Capa2) #Capa final\n",
    "    red1.enlazar()\n",
    "    mov=0\n",
    "    while(game.end==0):\n",
    "        valor= choice([2.0,4.0,8.0,16.0,32.0])\n",
    "        entrada=[]\n",
    "        entrada.append(valor)\n",
    "        for fila in game.mesa:\n",
    "            for celda in fila:\n",
    "                entrada.append(celda)\n",
    "        red1.capinicial.getinput(normalizar(entrada))\n",
    "        red1.capinicial.Feeding()\n",
    "        \n",
    "        outp=red1.capfinal.output\n",
    "        i=0\n",
    "        maxx=0\n",
    "        i2=0\n",
    "        for xot in outp:\n",
    "            if(maxx<=xot):\n",
    "                i2=i\n",
    "                maxx=xot\n",
    "            i=i+1\n",
    "        x= game.movimiento(i2,valor)\n",
    "        game.verifica_multiplos(x,i2)\n",
    "        #print(game.mesa)\n",
    "        mov=mov+1\n",
    "    puntaje= MaxValoMesa(game.mesa)\n",
    "    return puntaje*mov\n",
    "\n",
    "Genetic1.Fitness=Evaluador2\n",
    "Genetic1.Evaluate()\n",
    "print(Genetic1.Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1728.0, 64.0, 7424.0, 3200.0, 416.0, 2784.0, 9472.0, 6656.0, 11264.0, 10752.0, 1792.0, 640.0, 1792.0, 11776.0, 3200.0, 3840.0, 4480.0, 13312.0, 3712.0, 1408.0, 14080.0, 10752.0, 4608.0, 10752.0, 3840.0, 4096.0, 7936.0, 7168.0, 4736.0, 23040.0, 6400.0, 9728.0, 10240.0, 5504.0, 1536.0, 1792.0, 7936.0, 7680.0, 3328.0, 10240.0, 1600.0, 11520.0, 4864.0, 2816.0, 1792.0, 5888.0, 7168.0, 1920.0, 11264.0, 1600.0, 1920.0, 768.0, 1984.0, 1728.0, 4352.0, 4864.0, 1344.0, 2816.0, 3840.0, 3712.0, 1600.0, 5120.0, 2560.0, 1536.0, 2432.0, 5504.0, 4736.0, 4224.0, 3200.0, 4352.0, 2816.0, 6400.0, 1280.0, 11008.0, 7424.0, 1632.0, 10752.0, 10752.0, 960.0, 1920.0, 4352.0, 5888.0, 768.0, 11776.0, 4096.0, 11776.0, 9984.0, 3936.0, 9472.0, 1600.0, 1856.0, 11520.0, 4224.0, 9472.0, 1280.0, 1216.0, 13056.0, 3328.0, 4736.0, 2304.0, 8704.0, 4224.0, 2688.0, 2048.0, 9408.0, 2304.0, 3360.0, 4608.0, 704.0, 10240.0, 4736.0, 1088.0, 4608.0, 7424.0, 4096.0, 11520.0, 10496.0, 3360.0, 2560.0, 2688.0, 10752.0, 4224.0, 6656.0, 7936.0, 10240.0, 1536.0, 4480.0, 288.0, 3456.0, 5376.0, 2304.0, 1280.0, 1920.0, 3840.0, 3584.0, 3456.0, 7680.0, 3072.0, 2688.0, 9216.0, 3200.0, 3968.0, 2560.0, 13312.0, 3584.0, 4992.0, 2304.0, 1088.0, 1728.0, 1920.0, 4864.0, 4352.0, 10240.0, 7424.0, 2176.0, 2176.0, 4352.0, 960.0, 4352.0, 5120.0, 3200.0, 1728.0, 4096.0, 10496.0, 8704.0, 4352.0, 1728.0, 2176.0, 15360.0, 3712.0, 1920.0, 11776.0, 3968.0, 960.0, 9984.0, 9472.0, 7168.0, 1216.0, 14336.0, 13312.0, 3968.0, 1472.0, 5888.0, 12800.0, 4864.0, 3072.0, 2304.0, 7424.0, 576.0, 640.0, 11008.0, 3200.0, 24064.0, 3200.0, 960.0, 4480.0, 4352.0, 1408.0, 3072.0, 1472.0, 4096.0, 5120.0, 2944.0, 4608.0, 4608.0, 2592.0, 4736.0, 9216.0, 1664.0, 3328.0, 4480.0, 2560.0, 4480.0, 1344.0, 3200.0, 3168.0, 2816.0, 960.0, 1088.0, 8448.0, 256.0, 4352.0, 64.0, 4736.0, 7680.0, 1088.0, 3968.0, 2176.0, 3200.0, 3712.0, 2304.0, 1728.0, 1664.0, 4224.0, 3968.0, 9216.0, 3712.0, 3584.0, 1728.0, 4096.0, 3456.0, 1728.0, 1088.0, 11776.0, 5888.0, 4864.0, 4864.0, 1856.0, 4224.0, 14592.0, 1664.0, 1024.0, 4096.0, 9984.0, 10240.0, 4096.0, 4480.0, 10496.0, 3328.0, 2176.0, 11776.0, 4992.0, 10240.0, 1088.0, 27136.0, 3072.0, 11520.0, 1408.0, 2432.0, 3072.0, 3168.0, 2208.0, 10752.0, 2944.0, 768.0, 4608.0, 3584.0, 352.0, 1344.0, 3840.0, 2048.0, 13824.0, 3584.0, 3456.0, 4480.0, 11264.0, 5888.0, 3072.0, 7936.0, 9216.0, 1600.0, 3264.0, 3328.0, 5120.0, 6400.0, 1408.0, 7296.0, 3328.0, 7424.0, 2944.0, 3840.0, 4736.0, 448.0, 4096.0, 3200.0, 2784.0, 1792.0, 12288.0, 3584.0, 4992.0, 3584.0, 768.0, 2976.0, 4224.0, 3712.0, 1088.0, 3456.0, 3712.0, 5376.0, 1408.0, 9216.0, 3712.0, 3712.0, 4736.0, 6912.0, 4096.0, 4224.0, 4224.0, 4352.0, 1856.0, 2304.0, 5120.0, 1536.0, 8448.0, 13312.0, 1664.0, 1792.0, 832.0, 3968.0, 1600.0, 5120.0, 4480.0, 3968.0, 5504.0, 2688.0, 2176.0, 11008.0, 2816.0, 3840.0, 3712.0, 13056.0, 4352.0, 2048.0, 4608.0, 1664.0, 4224.0, 6656.0, 6912.0, 2176.0, 1728.0, 4736.0, 8448.0, 15616.0, 3968.0, 5376.0, 3968.0, 19712.0, 1600.0, 5760.0, 8448.0, 3072.0, 7424.0, 8960.0, 4352.0, 3360.0, 4096.0, 1536.0, 1600.0, 2560.0, 4224.0, 4224.0, 1280.0, 6016.0, 1088.0, 3840.0, 13824.0, 11776.0, 3712.0, 7424.0, 1408.0, 4992.0, 10496.0, 13312.0, 3712.0, 10496.0, 2816.0, 3840.0, 15360.0, 3968.0, 2752.0, 9728.0, 14592.0, 1664.0, 3200.0, 2560.0, 2816.0, 4096.0, 2944.0, 2112.0, 8448.0, 4352.0, 768.0, 2112.0, 2688.0, 11264.0, 2240.0, 2432.0, 3456.0, 4512.0, 4736.0, 2432.0, 896.0, 11264.0, 7488.0, 4608.0, 10240.0, 9728.0, 1216.0, 4096.0, 3712.0, 3584.0, 3584.0, 9728.0, 3840.0, 2304.0, 12800.0, 896.0, 9984.0, 1152.0, 10752.0, 11008.0, 5504.0, 640.0, 4512.0, 2304.0, 1408.0, 4096.0, 3968.0, 4096.0, 2048.0, 6272.0, 1600.0, 3584.0, 1024.0, 11264.0, 7168.0, 4224.0, 3200.0, 1344.0, 1344.0, 3072.0, 3968.0, 4736.0, 2688.0, 4864.0, 1600.0, 1344.0, 8704.0, 1472.0, 3584.0, 1600.0, 3840.0, 1024.0, 1856.0, 2176.0, 10240.0, 832.0, 2432.0, 1984.0, 4224.0, 3584.0, 2112.0, 704.0, 2176.0, 1216.0, 1216.0, 1920.0, 2944.0, 896.0, 3712.0, 1472.0, 2176.0, 3968.0, 5632.0, 4224.0, 3712.0, 12032.0, 2304.0, 2112.0, 1408.0, 5760.0, 3712.0, 12032.0, 9472.0, 2880.0, 1536.0, 35328.0, 2560.0, 14080.0, 9216.0, 896.0, 4352.0, 768.0, 5632.0, 2304.0, 3200.0, 1344.0, 3648.0, 17280.0, 3968.0, 704.0, 2944.0, 2880.0, 2176.0, 2432.0, 2944.0, 9216.0, 3712.0, 2304.0, 3200.0, 1408.0, 2560.0, 3328.0, 3072.0, 1088.0, 1152.0, 3200.0, 5248.0, 9216.0, 4096.0, 4352.0, 4224.0, 2688.0, 6400.0, 4096.0, 2240.0, 3712.0, 4096.0, 1600.0, 4224.0, 6144.0, 3328.0, 4224.0, 9984.0, 3840.0, 5248.0, 4864.0, 11264.0, 12288.0, 6400.0, 288.0, 1344.0, 1792.0, 3968.0, 3456.0, 4992.0, 2944.0, 11520.0, 11008.0, 3072.0, 1536.0, 3584.0, 5248.0, 10752.0, 7424.0, 4352.0, 4864.0, 3584.0, 9728.0, 3584.0, 9984.0, 6912.0, 6912.0, 8704.0, 10752.0, 4992.0, 5568.0, 4736.0, 24576.0, 3264.0, 4736.0, 2688.0, 5760.0, 2624.0, 4224.0, 1152.0, 4992.0, 4992.0, 9984.0, 3968.0, 14080.0, 256.0, 1024.0, 8448.0, 4736.0, 3072.0, 4480.0, 3200.0, 1088.0, 384.0, 2368.0, 2304.0, 8704.0, 1216.0, 6912.0, 2816.0, 5120.0, 4992.0, 3456.0, 4480.0, 3840.0, 4352.0, 4608.0, 1152.0, 14080.0, 9728.0, 3584.0, 5376.0, 2688.0, 1984.0, 1792.0, 4480.0, 4736.0, 11264.0, 3072.0, 11520.0, 1856.0, 9984.0, 768.0, 3584.0, 3584.0, 14080.0, 1728.0, 5888.0, 4736.0, 4864.0, 2240.0, 3840.0, 1920.0, 5504.0, 1024.0, 3328.0, 3840.0, 3840.0, 288.0, 7104.0, 17152.0, 6144.0, 2112.0, 6272.0, 1792.0, 3072.0, 10752.0, 1664.0, 12032.0, 4736.0, 2560.0, 10240.0, 1472.0, 1216.0, 3584.0, 5760.0, 4736.0, 10240.0, 2176.0, 9984.0, 1152.0, 10240.0, 3712.0, 15616.0, 1792.0, 1792.0, 5120.0, 3968.0, 6912.0, 896.0, 3200.0, 1024.0, 640.0, 2304.0, 7936.0, 9216.0, 8704.0, 768.0, 10496.0, 1600.0, 10496.0, 1152.0, 4864.0, 11520.0, 2496.0, 1792.0, 1664.0, 2400.0, 3328.0, 3072.0, 6400.0, 5952.0, 3584.0, 4480.0, 4096.0, 6912.0, 2176.0, 2176.0, 8960.0, 3264.0, 1152.0, 9600.0, 6784.0, 8960.0, 12032.0, 9216.0, 3968.0, 3712.0, 2688.0, 3840.0, 3584.0, 10176.0, 704.0, 3328.0, 12800.0, 3840.0, 4096.0, 1280.0, 5120.0, 3840.0, 4096.0, 608.0, 3840.0, 1088.0, 2304.0, 3328.0, 4736.0, 2944.0, 2816.0, 5248.0, 12288.0, 4352.0, 2176.0, 12800.0, 1472.0, 5888.0, 1152.0, 3200.0, 3200.0, 9984.0, 8960.0, 4736.0, 14592.0, 1152.0, 8448.0, 9728.0, 5376.0, 2816.0, 4736.0, 1664.0, 3456.0, 19968.0, 1600.0, 4480.0, 6912.0, 2688.0, 9472.0, 3584.0, 1856.0, 3968.0, 1472.0, 5760.0, 1536.0, 3840.0, 9472.0, 9728.0, 3456.0, 3712.0, 11776.0, 1984.0, 3712.0, 768.0, 2816.0, 4352.0, 14848.0, 10240.0, 6912.0, 3072.0, 4608.0, 11776.0, 9472.0, 4224.0, 816.0, 11776.0, 1600.0, 4864.0, 4608.0, 288.0, 1280.0, 2560.0, 9216.0, 6336.0, 12032.0, 5248.0, 2976.0, 1408.0, 3968.0, 2304.0, 3744.0, 8704.0, 1152.0, 3584.0, 4736.0, 4736.0, 8192.0, 1152.0, 4096.0, 12032.0, 14336.0, 4608.0, 11776.0, 3840.0, 5504.0, 11520.0, 4352.0, 4096.0, 480.0, 2752.0, 3456.0, 2432.0, 1600.0, 2432.0, 832.0, 2880.0, 2048.0, 2048.0, 10240.0, 9472.0, 14336.0, 2592.0, 7680.0, 4224.0, 4352.0, 11328.0, 11520.0, 5760.0, 12032.0, 1280.0, 5504.0, 640.0, 1472.0, 9984.0, 1024.0, 4864.0, 8960.0, 3968.0, 11264.0, 1440.0, 6912.0, 9216.0, 1408.0, 4864.0, 3968.0, 1024.0, 2176.0, 416.0, 2304.0, 3968.0, 4096.0, 3968.0, 5248.0, 3584.0, 3200.0, 6400.0, 12032.0, 128.0, 2432.0, 4352.0, 4224.0, 3072.0, 3968.0, 896.0, 3968.0, 3584.0, 1536.0, 3712.0, 4096.0, 9600.0, 2816.0, 3584.0, 3200.0, 1920.0, 2784.0, 3584.0, 1728.0, 2432.0, 12032.0, 3328.0, 1728.0, 10240.0, 1344.0, 3200.0, 4992.0, 3968.0, 1920.0, 2816.0, 3840.0, 9472.0, 5888.0, 1472.0, 2688.0, 4224.0, 14080.0, 3456.0, 1152.0, 1152.0, 3712.0, 2880.0, 1344.0, 10496.0, 4352.0, 1088.0, 2496.0, 3264.0, 1664.0, 4224.0, 1536.0, 4352.0, 3968.0, 1216.0, 16640.0, 896.0, 3584.0, 7680.0, 4224.0, 4608.0, 2016.0, 8960.0, 11008.0, 3456.0, 224.0, 4736.0, 1792.0, 4352.0, 12800.0, 1280.0, 1920.0, 9728.0, 13312.0, 4864.0, 3840.0, 10496.0, 3712.0, 8960.0, 4480.0, 11008.0, 9984.0, 4736.0, 4224.0, 11520.0, 11520.0, 4480.0, 4224.0, 1824.0, 3840.0, 3840.0, 4352.0, 1536.0, 3584.0, 14336.0, 3712.0, 3584.0, 5120.0, 11264.0, 7680.0, 5632.0, 608.0, 2304.0, 3072.0, 1600.0, 2432.0, 14592.0, 4864.0, 3456.0, 10752.0, 4992.0, 6720.0, 6656.0, 3456.0, 2304.0, 1216.0, 2880.0, 3712.0, 9728.0]\n"
     ]
    }
   ],
   "source": [
    "for x in range(200):\n",
    "    Genetic1.Reproduction()\n",
    "    Genetic1.Evaluate()\n",
    "print(Genetic1.Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506 35328.0\n",
      "ss\n",
      "[[ 0.  2.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "1\n",
      "[[  0.   2.  32.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "2\n",
      "[[  0.   2.  32.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "3\n",
      "[[  0.   2.  32.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "4\n",
      "[[  0.   2.  32.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "5\n",
      "[[  0.   8.  32.]\n",
      " [  0.   0.  16.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "6\n",
      "[[  0.  64.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "7\n",
      "[[  0.  64.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "8\n",
      "[[  0.  64.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "9\n",
      "[[  0.  64.  32.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "10\n",
      "[[  0.  64.  32.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "11\n",
      "[[  0.  64.  32.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "12\n",
      "[[  4.  64.  32.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "13\n",
      "[[  8.  64.  32.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   8.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "14\n",
      "[[  8.  64.  32.]\n",
      " [  4.   8.   0.]\n",
      " [  0.   2.   0.]\n",
      " [  0.   4.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]\n",
      " [  0.   0.   0.]]\n",
      "15\n",
      "[[   4.   16.  128.]\n",
      " [   0.    2.    0.]\n",
      " [   0.    4.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "16\n",
      "[[   4.   16.  128.]\n",
      " [   0.    2.    0.]\n",
      " [   0.    4.    0.]\n",
      " [   0.    8.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "17\n",
      "[[   4.   16.  128.]\n",
      " [   0.    2.   32.]\n",
      " [   0.    4.    0.]\n",
      " [   0.    8.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "18\n",
      "[[   4.   16.  128.]\n",
      " [   8.    2.   32.]\n",
      " [   0.    4.    0.]\n",
      " [   0.    8.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "19\n",
      "[[   4.   16.  128.]\n",
      " [   8.    2.   64.]\n",
      " [   0.    4.    0.]\n",
      " [   0.    8.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "20\n",
      "[[   4.   16.  128.]\n",
      " [   8.    2.   64.]\n",
      " [   0.    4.   32.]\n",
      " [   0.    8.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "21\n",
      "[[   4.   16.  256.]\n",
      " [   8.    2.    0.]\n",
      " [   0.    4.    0.]\n",
      " [   0.    8.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "22\n",
      "[[   4.   16.  256.]\n",
      " [  16.    2.    0.]\n",
      " [   0.    4.    0.]\n",
      " [   0.    8.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "23\n",
      "[[   4.   16.  256.]\n",
      " [  16.    2.   16.]\n",
      " [   0.    4.    0.]\n",
      " [   0.    8.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "24\n",
      "[[   4.   16.  256.]\n",
      " [  16.    2.   16.]\n",
      " [   8.    4.    0.]\n",
      " [   0.    8.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "25\n",
      "[[   4.   16.  256.]\n",
      " [  16.    2.   32.]\n",
      " [   8.    4.    0.]\n",
      " [   0.    8.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "26\n",
      "[[   4.   16.  256.]\n",
      " [  16.    2.   32.]\n",
      " [   8.    4.    0.]\n",
      " [   4.    8.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "27\n",
      "[[   4.   16.  256.]\n",
      " [  16.    2.   32.]\n",
      " [  24.    4.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "28\n",
      "[[   4.   16.  256.]\n",
      " [  16.    2.   32.]\n",
      " [  24.    8.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "29\n",
      "[[   4.   16.  256.]\n",
      " [  16.    2.   32.]\n",
      " [  24.   16.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "30\n",
      "[[   4.   16.  256.]\n",
      " [  16.    2.   64.]\n",
      " [  24.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "31\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "32\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    8.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "33\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    8.    0.]\n",
      " [   0.   16.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "34\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    8.   16.]\n",
      " [   0.   16.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "35\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    8.   16.]\n",
      " [   2.   16.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "36\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    8.   48.]\n",
      " [   2.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "37\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    8.   48.]\n",
      " [   2.   16.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "38\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    8.   48.]\n",
      " [   2.    0.   32.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "39\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    8.   48.]\n",
      " [   2.   16.   32.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "40\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    8.   48.]\n",
      " [   2.   16.   64.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "41\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    8.   48.]\n",
      " [   2.   16.   64.]\n",
      " [  16.    0.    0.]\n",
      " [   0.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "42\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    8.   48.]\n",
      " [   2.   16.   64.]\n",
      " [  16.    0.    0.]\n",
      " [   2.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "43\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    8.   48.]\n",
      " [   2.   16.   64.]\n",
      " [  16.    0.   16.]\n",
      " [   2.    0.    0.]\n",
      " [   0.    0.    0.]]\n",
      "44\n",
      "[[   4.   16.  256.]\n",
      " [  16.    4.   64.]\n",
      " [  24.    8.   48.]\n",
      " [   2.   16.   64.]\n",
      " [  16.    0.   16.]\n",
      " [   2.    0.    0.]\n",
      " [  16.    0.    0.]]\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "def buscarmax(lista):\n",
    "    i=0\n",
    "    maxx=0\n",
    "    for x in range(len(lista)):\n",
    "        if (lista[x]>maxx):\n",
    "            maxx=lista[x]\n",
    "            i=x\n",
    "    print(i,maxx)\n",
    "    return i\n",
    "mejor= buscarmax(Genetic1.Evaluation)\n",
    "\n",
    "verjugar(Genetic1.Population[mejor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Redes Iniciales--------Generaciones-------------Mejor Jugador--------------------MejorJuego\n",
    "       500                   100                      43                             32   en 10 juegos\n",
    "       500                   200                      50                             35   en 10 juegos  \n",
    "       500                   400                      59                             33   en 10 juegos \n",
    "       1000                  500                      85                             51   en 10 juegos \n",
    "       1000                  700                      77                             56   en 10 juegos \n",
    "       500               200 200                     17 y 256                        33   en 10 juegos \n",
    "       1000              200 200                     58  y 384                       50  61       \n",
    "       1000              200 200 200                 67 512 35328.0                  49  67  80  10 juegos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
